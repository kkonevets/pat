{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from common import *\n",
    "\n",
    "from asyncio.events import  AbstractEventLoop\n",
    "import logging\n",
    "import os, time\n",
    "from numba import jit\n",
    "import tflearn\n",
    "from tflearn.layers.core import time_distributed\n",
    "from tflearn.layers import conv_2d\n",
    "from io import StringIO\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "os.environ['PYTHONASYNCIODEBUG'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(text):\n",
    "    strings = tf.string_split([text], delimiter='\\n')\n",
    "    raw_nums = tf.string_split(strings.values)\n",
    "    nums = tf.string_to_number(raw_nums.values, tf.int32)\n",
    "\n",
    "    dense = tf.sparse_to_dense(raw_nums.indices, \n",
    "                               raw_nums.dense_shape, \n",
    "                               nums,\n",
    "                               default_value=0)\n",
    "#     dense.set_shape(raw_nums.get_shape())\n",
    "    return dense\n",
    "\n",
    "\n",
    "def read_input_tuple(filename_queue):\n",
    "    fnames = filename_queue.dequeue()\n",
    "    for fn in tf.unstack(fnames):\n",
    "        record_string = tf.read_file(fn)\n",
    "#         example = parse_csv(record_string)\n",
    "#     processed_example = some_processing(example)\n",
    "#     return example, key\n",
    "    return record_string\n",
    "\n",
    "\n",
    "def input_pipeline(filenames, batch_size, num_epochs=None):\n",
    "    string_tensor = tf.convert_to_tensor(filenames, dtype=tf.string)\n",
    "    string_tensor = tf.identity(string_tensor)\n",
    "    filename_queue = tf.train.input_producer(\n",
    "        filenames, \n",
    "#         element_shape=[],\n",
    "        num_epochs=num_epochs, \n",
    "        capacity=32,\n",
    "        shuffle=False,\n",
    "        seed=0)\n",
    "    fn = read_input_tuple(filename_queue)    \n",
    "\n",
    "#     min_after_dequeue = 10000\n",
    "#     capacity = min_after_dequeue + 3 * batch_size\n",
    "#     example_batch, label_batch = tf.train.batch(\n",
    "#         [example, key], \n",
    "#         batch_size=batch_size, \n",
    "#         capacity=capacity,\n",
    "# #         min_after_dequeue=min_after_dequeue,\n",
    "#         dynamic_pad=True,\n",
    "#         allow_smaller_final_batch=True,\n",
    "#         num_threads=cpu_count\n",
    "#     )\n",
    "#     return example_batch, label_batch\n",
    "\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob('../data/corpus/*.txt')[100:112]\n",
    "filenames = np.reshape(filenames, (-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../data/corpus/5984bf58b6b11307a2638529.txt',\n",
       "        '../data/corpus/5984c732b6b113644f638532.txt',\n",
       "        '../data/corpus/5984bd1eb6b1136c756384f5.txt'],\n",
       "       ['../data/corpus/5984c1fdb6b1132b6863853e.txt',\n",
       "        '../data/corpus/5984cfd2b6b113399a6384f7.txt',\n",
       "        '../data/corpus/5984c4eeb6b1134ab8638530.txt'],\n",
       "       ['../data/corpus/5984cb0ab6b1130b9863852c.txt',\n",
       "        '../data/corpus/5984d818b6b1130a266384f1.txt',\n",
       "        '../data/corpus/5984dbd1b6b113237863853f.txt'],\n",
       "       ['../data/corpus/5984c861b6b1136d74638511.txt',\n",
       "        '../data/corpus/5984c20db6b1132c8e6384f7.txt',\n",
       "        '../data/corpus/5984bb6db6b11359be638527.txt']],\n",
       "      dtype='<U43')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'2 110 92 3935 2690 1109 1730\\n2 110 92 3935 2690 1109 1730 4174\\n17 213 179 607 118 763 193 2487 3979 1 399 617 8 462 6701 462 2228 3979 5162 732 502 1459 22514 769 3979 2487 1988 1027 16112 820 1756 469 732 502\\n'\n",
      "b'4 549 1498 1670 1204 3434 120629 40 2 240 21960 1190\\n4 549 1498 1670 1204 3434 120629 40 254 1190 18 197 1639 43 254 1190 110 1465 43 254 1190 1809 206 2229 196 601 2251 1946 2251 1449 1031 15384 40 71 1616 17 1809 206 2229 196\\n4 17 197 1639 43 254 1190 23 768\\n4 17 1465 43 254 1190 55 77 190 87 522 768 575 1946 2229 196\\n4 17 1946 2251 23 615 196\\n4 17 1946 2251 23 9227\\n2 240 21960 1190 18 2251 1449 1031 120629 40 71 573 41 3434 2229 196 601 2251 6 2909 179 43 254 1190 17 165 5 615 196 1946 2251 45 6 2909 179 43 23 768 711 221\\n2 17 45 615 196 23 9227 4677 1078\\n'\n",
      "b'2 5866 747 141 1190\\n104 236 209 95 105 2 5866 141 1168 1190 2154 6376 13420 1498 47401 24983 2060 26259 320 13127 17515 6034\\n2 5866 747 141 1190 77 1891 2802 18713 134 5568 5 842 119 405 3042 119 286 1522 19765 747 141 218 405 1230 179 401 165 55 1444 1225 653 769 218 405 2\\n141 19 1271 4774 1863 257 1444 1443 2771 1669 1225 1870 12446 218 5620 295 1190\\n104 236 209 95 73 1058 31402 7324 609 105 2 5866 141 1168 1190 3 1076 153 5866 141 87 5085 1190 232 2154 6376 13420 1498 47401 24983 2060 26259 320 13127 17515 6034 1168 1190 189 7221\\n828 2 1360 119 277 216 5 20 175 298 71 857 1360 326 147 175 18 137 1745 1225 364 67 619 119 1154 30 89 159\\n303 981 1415 1805\\n337 49 4117 156 57 2 1146 16872 5866 141 785 1190 884 309 492 109 4117 795 2979 1545 666 159\\n801 64 1250 6597 4117 102 232 141 3564 189 4939 119 277 352 27 861 1197 622 73 49 4117 95 4022 119 277 352 159\\n884 164\\n4045 5748\\n27960 132148\\n828 2 5568 747 141 159\\n6479 4779\\n1659 1415\\n5 842 119 52731 357 405 4942 107 198 814 1324 315 40693 295 129 218 405 1031\\n66 105 2 823 8616 202 750 25021 141 412 1228 2 3250 1244 194 119 64 963 10811 141 4966 998 120 3129 3302 2501 21124 1442 200 99 119 88 419 139437 959 2524 141 1891 2802 998\\n220 1063 2 11 2589 12446 614 18713 12886 141\\n105 249 247 1 1658 245 236 209 411 1100 12446 614 13907 141\\n774 249 1422 75 50\\n2 5866 747 141 1190 77 1891 2802 18713 134 5568 5 842 119 286 218 405 1230 107 198 814 1324 315 13564 165 55 1225 22937 1444 1630 218 405 13564 113 84 166 464 218 5620\\n523 105 247 1398 437 1 27 245 105 2\\n2 18 842 119 28 6439 32 405 3042 119 1230 107 198 814 1324 315 842 286 1522 19765 747 141 922 109 3284 917 1230 218 405 769 286 405 1225 22937 1444 5 84 166 464 218\\n842 806 119 28 3303 32\\n18 814 1324 315 842 5189 141 1230 15637 286 1522 553 119 842 52731 405 25986 206 1628 348 1654 3284 917 1230 1 4405 12886 3085 202 750\\n25986 560 119 521 917 1230 141 21931 276 1148 521342 2654 142 13278 218 405 286 405 1225 22937 1444 257 84 1654 464 19 1271 4774 1863 1443 2771 1669 1225 1870 408 2131 1236 1116 8827 1346\\n245 2 273 377 88 1906 12446 614 10811 141\\n2 1225 5866 141 1190 5 842 119 405 3042 119 286 1522 19765 747 141 218 405 1230 1630 814 17 2 193 1444 1225 653 1630 218 405 2\\n'\n",
      "b'2 6712\\n7 95 1518 609 8278 8260 272 6712 4051 1336 140 19 4051\\n105 51 7 441 18173 110 178 123 4051 179 607 640 6861\\n123 25 4051 996 7527 661 945 1740 758 219 78 1336 3543 14 91580 55 351 178 2248 65 1336 178 253 244 243 1336 185 152 233 96 96\\n1065 54 178 1624 152 178 550 253 55 1065 381 1 86 77 1130 205 178 1191 1130 1298 54 1336 2057 264 4051\\n104 7 95 1518 609 8278 8260 6712 4051 1336 140 19 4051\\n6712 4051 23 140 19 2\\n828 28 2 20836 6712 5 178 1527 12 13 54 55 920 659 3472 12 178 8 19 3108 417 167 1 3124 78 178 54 8 1065 659 1065 2366 159\\n2 432 1043 140 253 8186 73 1950\\n763 88 419 1587 640 4051\\n828 2 20836 6712 255 4051 1733 1336 5 20836 178 1065 54 891 659 78 1 47 758 3124 152 219 78 178 193 1596 659 47 86 1624 219 78 178 159\\n178 88 6826 3941 525 6193 6861 1336 985 164\\n715 539 178 543 2716 9677 2221 2304 3942 6221 1336\\n337 178 88 601 1336 63 1632 346 1336 551 63 4517 575 1218 7226 1587 484 12279 16408 63 6091 63\\n110 178 418 929 661 1430 422 13877 1336 3813 380 1336 5695 932 13578 6861 1336\\n26 88 709 13578 6861 5949 480 681 2385\\n110 178 4 1146 51086 80 8866 189 5436\\n213 104 7 441 18173 110 178 179 607 640 6861\\n774 213 312 123 25 4051 996 7527 661 945 1740 758 219 78 1336 3543 14 91580 55 351 178 2248 65 1336 178 253 244 243 1336 185 152 233 96 96 1065 54 178 55 1065 381\\n27 104 2 6712 139 19 16\\n2 6712 5 351 178 2248 65 1336 5068 33 681\\n178 13 54 1065 381 1065 381 819 62 5827\\n55 1624 152 178 550 253 233 96 96\\n178 55 123 4051 244 243 1336 93 152 233 96 96\\n819 152 93\\n2 23 75 50\\n3696 681 287\\n6519 3840 819 147 293 178 474 1651 178 171 540 65 1336\\n9600 54 178 819 268 66 555 4051 1191 1130\\n77 776 2 28\\n1948 7497 12279\\n129 123 25 4051 2822 7527 996 661 246 1740 344 268 1336 3543 14 178 1598 758 219 78 1336\\n122 253 306 381 183 148 23029 2 9762 306 381 20476 9644 48 1336 879 54 129 246 22434 381 1130 553 1191 1130 1336\\n306 110 381 264 25 4051 167805 510 86 381 11271 86 147 116 481 5721 13578 4051\\n626 178 1065 381 395 254 2992 422 1336 88 3556 205 25 4051\\n287 990 5519 4843 224 16528\\n49 104 2 88 634 18173\\n178 1777 123 25 4051 24856 996 7527 418 703 8875 1077 6861\\n189 661 1430 422 13877 1077 6861 925 1209 5850 2110 634 199 2548\\n168 178 1777 758 219 78 1336 9836 416 2992 422 3543 14 344 268\\n91580 726 7226 380 1336 41 710 1587 607 640 264 4051\\n2 6712 5 55 123 25 4051 178 1065 54 891 659 17 213 441 18173 179 607 640 6861 2 5 351 178 2248 65 1336 55 996 7527 661 945 1740 3543 14 1336 178 253 244 243\\n'\n",
      "Done training -- epoch limit reached\n",
      "--- 0.02421426773071289 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():  \n",
    "    tf.set_random_seed(0)\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "#         example_batch, label_batch = input_pipeline(filenames, batch_size=2, num_epochs=1)      \n",
    "        res = input_pipeline(filenames, batch_size=2, num_epochs=1)        \n",
    "        \n",
    "        init_local = tf.local_variables_initializer()\n",
    "        init_global = tf.global_variables_initializer()\n",
    "        sess.run([init_global, init_local])\n",
    "                \n",
    "        # Start input enqueue threads.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        try:\n",
    "            while not coord.should_stop():\n",
    "#                 batches, keys = sess.run([example_batch, label_batch])  \n",
    "                [fnq] = sess.run([res])  \n",
    "#                 time_distributed(batches, conv_2d, [num_filters, filter_sizes, strides])\n",
    "                print(fnq)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "        finally:\n",
    "            # When done, ask the threads to stop.\n",
    "            coord.request_stop()\n",
    "\n",
    "        # Wait for threads to finish.\n",
    "        coord.join(threads)        \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My input func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.data_flow_ops.FIFOQueue object at 0x7f75ba931550>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'dequeue_up_to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-6f11ad2edfb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0minit_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-6f11ad2edfb8>\u001b[0m in \u001b[0;36minput_pipeline\u001b[0;34m(filenames, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Create a training graph that starts by dequeuing a batch of examples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdequeue_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#     train_op = ...use 'inputs' to build the training part of the graph...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'dequeue_up_to'"
     ]
    }
   ],
   "source": [
    "num_threads=cpu_count\n",
    "\n",
    "def input_pipeline(filenames, batch_size, num_epochs=None):    \n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "      filenames, num_epochs=num_epochs, shuffle=False, seed=0)\n",
    "    example_queue, key = read_input_file(filename_queue)    \n",
    "\n",
    "    # Create a training graph that starts by dequeuing a batch of examples.\n",
    "    inputs = example_queue.dequeue_up_to(batch_size)\n",
    "#     train_op = ...use 'inputs' to build the training part of the graph...\n",
    "\n",
    "    \n",
    "#     min_after_dequeue = 10000\n",
    "#     capacity = min_after_dequeue + 3 * batch_size\n",
    "#     example_batch, label_batch = tf.train.batch(\n",
    "#         [example, key], \n",
    "#         batch_size=batch_size, \n",
    "#         capacity=capacity,\n",
    "# #         min_after_dequeue=min_after_dequeue,\n",
    "#         dynamic_pad=True,\n",
    "#         allow_smaller_final_batch=True,\n",
    "#         num_threads=cpu_count\n",
    "#     )\n",
    "#     return example_batch, label_batch\n",
    "    return inputs\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():  \n",
    "    tf.set_random_seed(0)\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        inputs = input_pipeline(filenames, batch_size=2, num_epochs=1)        \n",
    "        \n",
    "        init_local = tf.local_variables_initializer()\n",
    "        init_global = tf.global_variables_initializer()\n",
    "        sess.run([init_global, init_local])\n",
    "                \n",
    "        # Start input enqueue threads.\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        try:\n",
    "            while not coord.should_stop():\n",
    "                examples = sess.run([inputs, label_batch])  \n",
    "#                 time_distributed(batches, conv_2d, [num_filters, filter_sizes, strides])\n",
    "                pprint(keys)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "        finally:\n",
    "            # When done, ask the threads to stop.\n",
    "            coord.request_stop()\n",
    "\n",
    "        # Wait for threads to finish.\n",
    "        coord.join(threads)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Li4vZGF0YS9jb3JwdXMvNTk4NGQ4MThiNmIxMTMwYTI2NjM4NGYxLnR4dA'\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():  \n",
    "    tf.set_random_seed(0)\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        fn = tf.encode_base64(b'../data/corpus/5984d818b6b1130a266384f1.txt')\n",
    "#         res = tf.read_file(fn)\n",
    "        [cont] = sess.run([fn])\n",
    "        print(cont)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
