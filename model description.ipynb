{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск похожих патентов. Описание метода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По патенту-запросу найти наиболее похожие патенты отсортированные по релевантности в порядке убывания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Корпус состоит из примерно 1.2 млн. документов. Из них 368 тыс. имееют ссылки на другие документы в этом корпусе. Каждая такая ссылка являетя похожим документом на данный. Всего таких ссыллок 765 тыс., то есть в среднем 2 похожих документа на запрос. На этих размеченных данных обучается модель \"с учителем\".\n",
    "* В качестве непохожих примеров (отрицательных) можно выбрать все документы из корпуса не указанные пользователем в качестве похожих. Но есть более оптимальный подход - искать непохожие в рамках одного batch пакета.\n",
    "* Сырые тексты были лемматизированы и к ним применился алгоритм word2vec для получения векторных представлений слов на всем корпусе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-22T11:24:43.153576Z",
     "start_time": "2017-08-22T11:24:43.147963Z"
    }
   },
   "source": [
    "В качестве алгоритма были выбраны сверточные нейронные сети, на вход которым подавались вектора слов. Свертка происходит по векторным представлениям слов и предложений, что в лингвистике интуитивно соответствует свертке по n-граммам слов и предложений.\n",
    "\n",
    "**Архитектура сети**\n",
    "* Первый слой - свертка по словам для каждого предложения с фильтрами разной величины. Затем k-max pooling для полуения фиксированного вектора наиболее значимых фичей. На выходе - векторные представления предложений. Веса сети для каждого из предложений являются разделяемыми в рамках всей сети.\n",
    "* Второй слой - свертка по предложениям в рамках одного документа с фильтрами разной величины. Затем k-max pooling для полуения фиксированного вектора наиболее значимых фичей. На выходе - векторные представления документов.\n",
    "* Третий слой - L2 нормализация векторных представлений документов для преведения векторов документов к единому масштабу.\n",
    "\n",
    "**Loss function**\n",
    "\n",
    "В качестве минимизируемой функции была выбрана функция *Triplet Loss* с оптимизацией в рамках одного batch. Для алгоритма критически важно чтобы ему на вход подавались как положительные так и отрицательные примеры, причем степень похожести/непохожести должна быть сбалансирована."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Список литературы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Aliaksei Severyn and Alessandro Moschitti. Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks. SIGIR, 2015\n",
    "\n",
    "[2] Misha Denil, Alban Demiraj, Nal Kalchbrenner, Phil Blunsom, Nando de Freitas. Modelling, Visualising and Summarising Documents with a Single Convolutional Neural Network. 2015\n",
    "\n",
    "[3] Nal Kalchbrenner, Edward Grefenstette, Phil Blunsom. A Convolutional Neural Network for Modelling Sentences. 2014\n",
    "\n",
    "[4] Florian Schroff, Dmitry Kalenichenko, James Philbin. FaceNet: A Unified Embedding for Face Recognition and Clustering, 2015\n",
    "\n",
    "[5] Alexander Hermans, Lucas Beyer, Bastian Leibe. In Defense of the Triplet Loss for Person Re-Identification, 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
