{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from itertools import islice\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "DATA_FOLDER = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_docs = glob.iglob(os.path.join(DATA_FOLDER, 'FIPS') + '/**/*.txt', recursive=True)\n",
    "# corpus_file = open(DATA_FOLDER + 'corpus.txt', 'w')\n",
    "# for item in all_docs:\n",
    "#     corpus_file.write(\"%s\\n\" % os.path.relpath(item, DATA_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from nltk.tokenize.toktok import ToktokTokenizer \n",
    "# toktok = ToktokTokenizer()\n",
    "# toktok.tokenize('устройство по п . 3 , отличать тем , что оно снабжать устанавливать в головка винт , в который размещать шарик и ролик .  . ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = stopwords.words('russian')\n",
    "stop_list.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', 'к', 'на', 'ко'])\n",
    "stop_list.extend(list(string.punctuation))\n",
    "\n",
    "punkts = [s for s in string.punctuation if s not in '.!?']\n",
    "\n",
    "\n",
    "class Corpus(gensim.corpora.TextCorpus):\n",
    "    def get_texts(self):\n",
    "        for filename in tqdm(self.input): # for each relevant file\n",
    "            yield tokenize(open(filename).read())\n",
    "\n",
    "\n",
    "def tokenize(file_text):\n",
    "    tokens = nltk.word_tokenize(file_text)\n",
    "\n",
    "    tokens = [validate_word(word) for word in tokens if check_word(word)]\n",
    "    tokens = filter(lambda s: s != '', tokens)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "            \n",
    "def validate_word(word):\n",
    "    word = word.replace(\"«\", \"\").replace(\"»\", \"\").replace(\"`\", '').replace(\".\", '')\n",
    "    if len(word) == 1:\n",
    "        return ''\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "def check_word(word):\n",
    "    if word in stop_list:\n",
    "        return False\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# dfolder = os.path.join(DATA_FOLDER, 'FIPS/Inventions patents_txt_output/0c/0c')\n",
    "# all_docs = glob.glob(dfolder + '/**/*.txt', recursive=True)\n",
    "\n",
    "all_docs = glob.glob(os.path.join(DATA_FOLDER, 'FIPS') + '/**/*.txt', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus = Corpus(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus.dictionary.save(os.path.join(DATA_FOLDER, 'dict.dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpora.MmCorpus.serialize(os.path.join(DATA_FOLDER, 'corpus.mm'), corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpora.MmCorpus(os.path.join(DATA_FOLDER, 'corpus.mm'))\n",
    "print(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
