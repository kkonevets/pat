{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:44:41.774332Z",
     "start_time": "2017-07-17T12:44:24.692084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim.models import VocabTransform\n",
    "\n",
    "from common import *\n",
    "import os\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import copy \n",
    "\n",
    "from gzip import GzipFile\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count() -1\n",
    "DATA_FOLDER = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:52:36.845434Z",
     "start_time": "2017-07-17T12:52:36.824833Z"
    }
   },
   "outputs": [],
   "source": [
    "flist = sorted(glob(DATA_FOLDER + '/documents/*.gz'), key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:52:56.516345Z",
     "start_time": "2017-07-17T12:52:56.488612Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocumentCorpus(gensim.corpora.TextCorpus):\n",
    "    def get_texts(self):\n",
    "        for fn in tqdm(self.input): # for each relevant file\n",
    "            with GzipFile(fn, 'r') as myzip:\n",
    "                text = myzip.read()\n",
    "            docs = json.loads(text)\n",
    "            for doc in docs:\n",
    "                yield sum(doc, [])\n",
    "\n",
    "                \n",
    "def save_doc_corpus(ziped_files, dir_name, prefix):\n",
    "    corpus = DocumentCorpus(ziped_files)\n",
    "    \n",
    "    dic_name = join(dir_name, '%s.dict' % prefix)\n",
    "    corp_name = join(dir_name, '%s_corpus.mm' % prefix)\n",
    "    \n",
    "    corpus.dictionary.save(dic_name)\n",
    "    corpora.MmCorpus.serialize(corp_name, corpus)\n",
    "    \n",
    "    return dic_name, corp_name\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-17T12:53:02.629Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [36:04<00:00,  2.22s/it]\n",
      " 54%|█████▍    | 540/1001 [12:21<29:11,  3.80s/it]"
     ]
    }
   ],
   "source": [
    "save_doc_corpus(flist, DATA_FOLDER, 'pure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out tokens that appear in less than 5 documents (absolute number) or more than 50% documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# filter the dictionary\n",
    "old_dict = corpora.Dictionary.load(join(DATA_FOLDER, 'old.dict'))\n",
    "new_dict = copy.deepcopy(old_dict)\n",
    "new_dict.filter_extremes(no_below=3, keep_n=None)\n",
    "new_dict.save(join(DATA_FOLDER, 'filtered.dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# now transform the corpus\n",
    "corpus = corpora.MmCorpus(join(DATA_FOLDER, 'corpus.mm'))\n",
    "old2new = {old_dict.token2id[token]:new_id for new_id, token in new_dict.iteritems()}\n",
    "vt = VocabTransform(old2new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "corpora.MmCorpus.serialize(join(DATA_FOLDER, 'filtered_corpus.mm'), vt[corpus], id2word=new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '../data/*corpus*': No such file or directory\n",
      "cp: cannot stat '../data/*.dict': No such file or directory\n",
      "cp: cannot stat '../data/all_docs.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp ../data/*corpus* ~/Yandex.Disk\n",
    "!cp ../data/*.dict ~/Yandex.Disk\n",
    "!cp ../data/all_docs.txt ~/Yandex.Disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
