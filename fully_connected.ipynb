{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:46:13.279060Z",
     "start_time": "2017-09-26T09:46:11.999282Z"
    }
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot as plt\n",
    "import logging, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import data_flow\n",
    "import train\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:06:38.839918Z",
     "start_time": "2017-09-26T09:06:34.469119Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fnames = glob('../data/corpus/**.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:35:38.553028Z",
     "start_time": "2017-09-26T08:35:34.580028Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = np.load(join(DATA_FOLDER, 'word_embeddings_300.npy'))\n",
    "with open(join(DATA_FOLDER, \"dictionary.pickle\"), \"rb\") as input_file:\n",
    "    index2word = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:04:23.452500Z",
     "start_time": "2017-09-26T08:48:17.223947Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62aa0fc9711d4c489e0a292b15cd6f32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/corpus/5984b653b6b11311aa638537.txt\n",
      "../data/corpus/5984b69db6b1131591638547.txt\n",
      "../data/corpus/5984b6fdb6b1131ae26384f4.txt\n",
      "../data/corpus/5984b667b6b11313926384f7.txt\n",
      "../data/corpus/5984b690b6b113159263850f.txt\n",
      "../data/corpus/5984b65db6b1131294638541.txt\n",
      "../data/corpus/5984b6bab6b11317b963851c.txt\n",
      "../data/corpus/5984b592b6b113049f638531.txt\n",
      "../data/corpus/5984b6bab6b11317a16384fd.txt\n",
      "../data/corpus/5984b6a3b6b11316a563850e.txt\n",
      "../data/corpus/5984b589b6b11304986384fd.txt\n",
      "../data/corpus/5984b6c1b6b11317b0638527.txt\n",
      "../data/corpus/5984b6bbb6b11317a163852f.txt\n",
      "../data/corpus/5984b6bbb6b11317a1638546.txt\n",
      "../data/corpus/5984b58fb6b1130489638517.txt\n",
      "../data/corpus/5984b68fb6b11315926384f3.txt\n",
      "../data/corpus/5984b68fb6b1131592638508.txt\n",
      "../data/corpus/5984b58fb6b11304a963852e.txt\n",
      "../data/corpus/5984b6bbb6b11317a1638536.txt\n",
      "../data/corpus/5984b6a4b6b113169a638532.txt\n",
      "../data/corpus/5984b6bab6b11317a163850f.txt\n",
      "../data/corpus/5984b6c2b6b11317b8638545.txt\n",
      "../data/corpus/5984b6c1b6b11317b0638520.txt\n",
      "../data/corpus/5984b6fdb6b1131ae26384fd.txt\n",
      "../data/corpus/5984b6c1b6b11317b063852d.txt\n",
      "../data/corpus/5984b69db6b1131591638542.txt\n",
      "../data/corpus/5984b579b6b11303b0638513.txt\n",
      "../data/corpus/5984b6bab6b11317b9638508.txt\n",
      "../data/corpus/5984b6a4b6b113169a638540.txt\n",
      "../data/corpus/5984b6bab6b11317b963851d.txt\n",
      "../data/corpus/5984b578b6b11303b06384f9.txt\n",
      "../data/corpus/5984b6fdb6b1131ae263850c.txt\n",
      "../data/corpus/5984b6bbb6b11317a163852b.txt\n",
      "../data/corpus/5984b6bab6b11317b16384f8.txt\n",
      "../data/corpus/5984b6c2b6b11317b863852b.txt\n",
      "../data/corpus/5984b6c2b6b11317b8638525.txt\n",
      "../data/corpus/5984b6a3b6b11316a56384fb.txt\n",
      "../data/corpus/5984b6a4b6b113169a638519.txt\n",
      "../data/corpus/5984b6a4b6b113169a63852c.txt\n",
      "../data/corpus/5984b667b6b11313926384f8.txt\n",
      "../data/corpus/5984b64eb6b11310ea6384ef.txt\n",
      "../data/corpus/5984b667b6b11313766384fc.txt\n",
      "../data/corpus/5984b57cb6b11303ca638510.txt\n",
      "../data/corpus/5984b6bab6b11317a16384f4.txt\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "ids = []\n",
    "for fn in tqdm_notebook(fnames[:]):\n",
    "    with open(fn, 'rb') as f:\n",
    "        ixs = [int(_ix) for _ix in f.read().split()]\n",
    "    if len(ixs) == 0:\n",
    "        print(fn)\n",
    "        continue\n",
    "    doc_vec = word_embeddings[ixs].mean(axis=0)\n",
    "    docs.append(doc_vec)\n",
    "    ids.append(basename(fn).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:04:49.172909Z",
     "start_time": "2017-09-26T09:04:41.751331Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/avged_docs.npy', docs)\n",
    "np.save('../data/avged_ids.npy', ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:46:15.217648Z",
     "start_time": "2017-09-26T09:46:14.078764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(DATA_FOLDER, 'sims.json'), 'r') as f:\n",
    "    sims = json.load(f)\n",
    "with open(join(DATA_FOLDER, 'gold_mongo.json'), 'r') as f:\n",
    "    gold = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:46:17.945035Z",
     "start_time": "2017-09-26T09:46:15.219122Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = np.load('../data/avged_docs.npy')\n",
    "ids = np.load('../data/avged_ids.npy')\n",
    "docs = pd.DataFrame(docs, index=ids)\n",
    "docs.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# try unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T11:01:02.848615Z",
     "start_time": "2017-09-25T11:00:16.709851Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad3c1ef51844f299a2002e6c9851a33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_vecs = []\n",
    "for _id in tqdm_notebook(gold.keys()):\n",
    "    ix = np.where(ids == _id)[0][0]\n",
    "    val_vecs.append(docs[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T11:02:09.658857Z",
     "start_time": "2017-09-25T11:02:06.815765Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sim_mat = cosine_similarity(val_vecs, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T11:03:48.973662Z",
     "start_time": "2017-09-25T11:03:20.726512Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:28<00:00,  6.53it/s]\n"
     ]
    }
   ],
   "source": [
    "best = {}\n",
    "for i, vec in enumerate(tqdm(sim_mat)):\n",
    "    val_name = gold.keys()[i]\n",
    "    train_ixs = vec.argsort()[-200:][::-1]\n",
    "    top_train = [ids[i] for i in train_ixs]\n",
    "    best[val_name] = top_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T11:04:36.591760Z",
     "start_time": "2017-09-25T11:04:36.032170Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:00<00:00, 16783.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median\n",
      "acc10     0.0\n",
      "acc20     0.0\n",
      "acc200    0.5\n",
      "dtype: float64\n",
      "mean\n",
      "acc10     0.273007\n",
      "acc20     0.355435\n",
      "acc200    0.535145\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TGGfSS1DiDXpIa93+FomNWdYPIdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d630fc490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEWpJREFUeJzt3X+QXWV9x/H3RyKixCYodocJ1NARtQyMFXYsDjN0I7YT\noRU6OhbHH8HSZsbfVduattPR/hyciorUqY1iiQ41KnVMRrQOg2yZdgo1wR9BkJJi1KRItEDaiK2l\nfvvHPbErgntzz9292Wffrxkm95x7znm+393wydnn3vtsqgpJUrseNekCJEkLy6CXpMYZ9JLUOINe\nkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNW7FpAsAOP7442vt2rUjnfud73yHY489drwFHeHseXmw\n5+WhT887d+78dlU9ab7jjoigX7t2LTt27Bjp3NnZWWZmZsZb0BHOnpcHe14e+vSc5GvDHOfUjSQ1\nzqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNe6I+GRsH7v2HeDiTddOZOw9l54/\nkXEl6XB4Ry9JjTPoJalxBr0kNW7eoE/ygST7k9w6Z98TklyX5M7uz+O6/Uny7iS7k3wpyRkLWbwk\naX7D3NFfBax/yL5NwPVVdQpwfbcN8DzglO6/jcBfjqdMSdKo5g36qroRuPchuy8AtnSPtwAXztn/\nwRq4CVid5IRxFStJOnyjztFPVdXd3eNvAlPd4zXAN+Yct7fbJ0makN7vo6+qSlKHe16SjQymd5ia\nmmJ2dnak8aceC286/cGRzu1r1Jr7Onjw4MTGnhR7Xh7seWGMGvT3JDmhqu7upmb2d/v3ASfNOe7E\nbt+PqKrNwGaA6enpGvVXaV1x9TYu2zWZz33tecnMRMb1160tD/a8PCxGz6NO3WwHNnSPNwDb5ux/\neffum7OAA3OmeCRJEzDvrXCSDwMzwPFJ9gJvAS4FPprkEuBrwIu6wz8FnAfsBh4AXrEANUuSDsO8\nQV9VL36Ep859mGMLeHXfoiRJ4+MnYyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN\nM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiD\nXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJalyvoE/yhiRf\nTnJrkg8nOSbJyUluTrI7yUeSHD2uYiVJh2/koE+yBngdMF1VpwFHARcBbwPeWVVPAe4DLhlHoZKk\n0fSdulkBPDbJCuBxwN3Ac4Bruue3ABf2HEOS1MPIQV9V+4C3A19nEPAHgJ3A/VX1YHfYXmBN3yIl\nSaNLVY12YnIc8LfArwL3Ax9jcCf/1m7ahiQnAZ/upnYeev5GYCPA1NTUmVu3bh2pjv33HuCe7450\nam+nr1k1kXEPHjzIypUrJzL2pNjz8mDPh2fdunU7q2p6vuNWjHT1gecCX62qbwEk+ThwNrA6yYru\nrv5EYN/DnVxVm4HNANPT0zUzMzNSEVdcvY3LdvVpY3R7XjIzkXFnZ2cZ9eu1VNnz8mDPC6PPHP3X\ngbOSPC5JgHOB24AbgBd2x2wAtvUrUZLUR585+psZTNXcAuzqrrUZeDPwxiS7gScCV46hTknSiHrN\neVTVW4C3PGT3XcCz+lxXkjQ+fjJWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiD\nXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+gl\nqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Qr6JKuTXJPk\nK0luT/LsJE9Icl2SO7s/jxtXsZKkw9f3jv5y4O+q6unAM4DbgU3A9VV1CnB9ty1JmpCRgz7JKuAc\n4EqAqvpeVd0PXABs6Q7bAlzYt0hJ0uhSVaOdmPwssBm4jcHd/E7g9cC+qlrdHRPgvkPbDzl/I7AR\nYGpq6sytW7eOVMf+ew9wz3dHOrW309esmsi4Bw8eZOXKlRMZe1LseXmw58Ozbt26nVU1Pd9xfYJ+\nGrgJOLuqbk5yOfAfwGvnBnuS+6rqx87TT09P144dO0aq44qrt3HZrhUjndvXnkvPn8i4s7OzzMzM\nTGTsSbHn5cGeD0+SoYK+zxz9XmBvVd3cbV8DnAHck+SErogTgP09xpAk9TRy0FfVN4FvJHlat+tc\nBtM424EN3b4NwLZeFUqSeuk75/Fa4OokRwN3Aa9g8I/HR5NcAnwNeFHPMSRJPfQK+qr6AvBw80Pn\n9rmuJGl8/GSsJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXGTWQ1Mko4gazddO7Gx\nr1p/7IKP4R29JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLU\nOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuN6B32So5J8Pskn\nu+2Tk9ycZHeSjyQ5un+ZkqRRjeOO/vXA7XO23wa8s6qeAtwHXDKGMSRJI+oV9ElOBM4H3t9tB3gO\ncE13yBbgwj5jSJL66XtH/y7gd4Dvd9tPBO6vqge77b3Amp5jSJJ6SFWNdmLyS8B5VfWqJDPAbwEX\nAzd10zYkOQn4dFWd9jDnbwQ2AkxNTZ25devWkerYf+8B7vnuSKf2dvqaVRMZ9+DBg6xcuXIiY0+K\nPS8Pk+p5174Diz7mISevOmrkntetW7ezqqbnO27FSFcfOBt4fpLzgGOAnwAuB1YnWdHd1Z8I7Hu4\nk6tqM7AZYHp6umZmZkYq4oqrt3HZrj5tjG7PS2YmMu7s7Cyjfr2WKnteHibV88Wbrl30MQ+5av2x\nC97zyFM3VfW7VXViVa0FLgI+W1UvAW4AXtgdtgHY1rtKSdLIFuJ99G8G3phkN4M5+ysXYAxJ0pDG\nMudRVbPAbPf4LuBZ47iuJKk/PxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxB\nL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS\n1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjRg76JCcluSHJ\nbUm+nOT13f4nJLkuyZ3dn8eNr1xJ0uHqc0f/IPCmqjoVOAt4dZJTgU3A9VV1CnB9ty1JmpCRg76q\n7q6qW7rH/wncDqwBLgC2dIdtAS7sW6QkaXRjmaNPshZ4JnAzMFVVd3dPfROYGscYkqTRpKr6XSBZ\nCfw98KdV9fEk91fV6jnP31dVPzJPn2QjsBFgamrqzK1bt440/v57D3DPd0erva/T16yayLgHDx5k\n5cqVExl7Uux5eZhUz7v2HVj0MQ85edVRI/e8bt26nVU1Pd9xvYI+yaOBTwKfqap3dPvuAGaq6u4k\nJwCzVfW0H3ed6enp2rFjx0g1XHH1Ni7btWKkc/vac+n5Exl3dnaWmZmZiYw9Kfa8PEyq57Wbrl30\nMQ+5av2xI/ecZKig7/OumwBXArcfCvnOdmBD93gDsG3UMSRJ/fW5FT4beBmwK8kXun2/B1wKfDTJ\nJcDXgBf1K1GS1MfIQV9V/wDkEZ4+d9TrSpLGy0/GSlLjJvMqprRETPpFOmkcvKOXpMYZ9JLUOINe\nkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWp\ncQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJatyKSRegpWXtpmsnMu5V64+dyLhSC7yjl6TGGfSS\n1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQvyPvok64HLgaOA91fVpQsxjtSyXfsOcPEEPrew59Lz\nF31MLayx39EnOQp4D/A84FTgxUlOHfc4kqThLMQd/bOA3VV1F0CSrcAFwG0LMNZE+SnRxTOpu1up\nBQsxR78G+Mac7b3dPknSBKSqxnvB5IXA+qr69W77ZcDPVdVrHnLcRmBjt/k04I4Rhzwe+PaI5y5V\n9rw82PPy0KfnJ1fVk+Y7aCGmbvYBJ83ZPrHb90OqajOwue9gSXZU1XTf6ywl9rw82PPysBg9L8TU\nzeeAU5KcnORo4CJg+wKMI0kawtjv6KvqwSSvAT7D4O2VH6iqL497HEnScBbkffRV9SngUwtx7YfR\ne/pnCbLn5cGel4cF73nsL8ZKko4sLoEgSY1bMkGfZH2SO5LsTrLpYZ5/TJKPdM/fnGTt4lc5XkP0\n/MYktyX5UpLrkzx5EnWO03w9zznuBUkqyZJ/h8YwPSd5Ufe9/nKSv1nsGsdtiL/bP5XkhiSf7/5+\nnzeJOsclyQeS7E9y6yM8nyTv7r4eX0pyxlgLqKoj/j8GL+r+K/DTwNHAF4FTH3LMq4D3do8vAj4y\n6boXoed1wOO6x69cDj13xz0euBG4CZiedN2L8H0+Bfg8cFy3/ZOTrnsRet4MvLJ7fCqwZ9J19+z5\nHOAM4NZHeP484NNAgLOAm8c5/lK5o//BsgpV9T3g0LIKc10AbOkeXwOcmySLWOO4zdtzVd1QVQ90\nmzcx+MzCUjbM9xngj4G3Af+1mMUtkGF6/g3gPVV1H0BV7V/kGsdtmJ4L+Inu8Srg3xaxvrGrqhuB\ne3/MIRcAH6yBm4DVSU4Y1/hLJeiHWVbhB8dU1YPAAeCJi1LdwjjcpSQuYXBHsJTN23P3I+1JVdXK\nwjfDfJ+fCjw1yT8mualbHXYpG6bntwIvTbKXwTv4Xrs4pU3Mgi4dsyBvr9TiSvJSYBr4+UnXspCS\nPAp4B3DxhEtZbCsYTN/MMPip7cYkp1fV/ROtamG9GLiqqi5L8mzgQ0lOq6rvT7qwpWip3NEPs6zC\nD45JsoLBj3v/vijVLYyhlpJI8lzg94HnV9V/L1JtC2W+nh8PnAbMJtnDYC5z+xJ/QXaY7/NeYHtV\n/U9VfRX4FwbBv1QN0/MlwEcBquqfgGMYrAnTqqH+fx/VUgn6YZZV2A5s6B6/EPhsda9yLFHz9pzk\nmcBfMQj5pT5vC/P0XFUHqur4qlpbVWsZvC7x/KraMZlyx2KYv9ufYHA3T5LjGUzl3LWYRY7ZMD1/\nHTgXIMnPMAj6by1qlYtrO/Dy7t03ZwEHqurucV18SUzd1CMsq5Dkj4AdVbUduJLBj3e7GbzocdHk\nKu5vyJ7/HFgJfKx73fnrVfX8iRXd05A9N2XInj8D/GKS24D/BX67qpbsT6tD9vwm4H1J3sDghdmL\nl/KNW5IPM/jH+vjudYe3AI8GqKr3Mngd4jxgN/AA8Iqxjr+Ev3aSpCEslakbSdKIDHpJapxBL0mN\nM+glqXEGvSQ1zqCXhpDkcUmuTfKVbgXJS+c819zKqWqLQS8N7+1V9XTgmcDZSZ7X7b8EuK+qngK8\nk8GCa9IRw6DXspHkE0l2dnfkG7t965PckuSLSa7v9q1M8tdJdnVrg7+gqh6oqhsAuhUXb+H/Vwtt\nbeVUNWZJfDJWGpNfq6p7kzwW+FySbcD7gHOq6qtJntAd9wcMPoJ+OkCS4+ZeJMlq4JeBy7tdP7Ry\napJDK6d+e8E7koZg0Gs5eV2SX+kenwRsBG7sFgqjqg6tF/5c5iyhcWgdePjBgnkfBt5dVUt5vRkt\nI07daFlIMsMgwJ9dVc9g8BubvjDCpTYDd1bVu+bsa23lVDXGoNdysYrBC6YPJHk6gyWOjwHOSXIy\nwJypm+uAVx868dDUTZI/6a7zmw+5dmsrp6oxLmqmZSHJYxgs97sWuANYzeC3GD0W+DMGNz37q+oX\nkqwE3gOcyWC1yD8E/pnBPPxXgEPr/v9FVb0/yTHAhxi8G+de4CKndXQkMeglqXFO3UhS4wx6SWqc\nQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIa93/0AAiVOUlPwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d6312c790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1IhDHRJKoSBLkmFMNAlqRAGuiQV4v8BxQnXXneJuLIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d60743350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = evaluate(best, gold)\n",
    "\n",
    "ax = result['acc10'].hist()\n",
    "ax.set_xlabel(\"acc10\")\n",
    "plt.show()\n",
    "\n",
    "ax = result['acc20'].hist()\n",
    "ax.set_xlabel(\"acc20\")\n",
    "plt.show()\n",
    "\n",
    "ax = result['acc200'].hist()\n",
    "ax.set_xlabel(\"acc200\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:46:24.532426Z",
     "start_time": "2017-09-26T09:46:17.946606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368458/368458 [00:04<00:00, 87415.00it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_all = list(data_flow.random_triples(sims, ids, num_epochs=1, with_path=False, seed=1))\n",
    "_triples, triples_test = train_test_split(triples_all, test_size=0.1, random_state=0)\n",
    "triples_train, triples_val = train_test_split(_triples, test_size=0.1, random_state=0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T09:46:16.606Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "sizes=[300, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-26T09:46:20.680Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-26 12:46:24,568 [MainThread  ] [INFO ]  start training ...\n",
      "2017-09-26 12:46:26,790 [MainThread  ] [INFO ]  step 0, loss 0.0246231\n",
      "2017-09-26 12:46:26,816 [MainThread  ] [INFO ]  step 1, loss 0.193446\n",
      "2017-09-26 12:46:26,942 [MainThread  ] [INFO ]  step 2, loss 0.138571\n",
      "2017-09-26 12:46:26,960 [MainThread  ] [INFO ]  step 3, loss 0.0880808\n",
      "2017-09-26 12:46:26,973 [MainThread  ] [INFO ]  step 4, loss 0.108038\n",
      "2017-09-26 12:46:26,986 [MainThread  ] [INFO ]  step 5, loss 0.0834588\n",
      "2017-09-26 12:46:27,002 [MainThread  ] [INFO ]  step 6, loss 0.0840769\n",
      "2017-09-26 12:46:27,019 [MainThread  ] [INFO ]  step 7, loss 0.0736942\n",
      "2017-09-26 12:46:27,036 [MainThread  ] [INFO ]  step 8, loss 0.0898689\n",
      "2017-09-26 12:46:27,050 [MainThread  ] [INFO ]  step 9, loss 0.0562397\n",
      "2017-09-26 12:46:27,065 [MainThread  ] [INFO ]  step 10, loss 0.0427516\n",
      "2017-09-26 12:46:27,084 [MainThread  ] [INFO ]  step 11, loss 0.0902829\n",
      "2017-09-26 12:46:27,100 [MainThread  ] [INFO ]  step 12, loss 0.0716068\n",
      "2017-09-26 12:46:27,118 [MainThread  ] [INFO ]  step 13, loss 0.0863679\n",
      "2017-09-26 12:46:27,135 [MainThread  ] [INFO ]  step 14, loss 0.0734166\n",
      "2017-09-26 12:46:27,151 [MainThread  ] [INFO ]  step 15, loss 0.0851122\n",
      "2017-09-26 12:46:27,164 [MainThread  ] [INFO ]  step 16, loss 0.0395469\n",
      "2017-09-26 12:46:27,178 [MainThread  ] [INFO ]  step 17, loss 0.0571821\n",
      "2017-09-26 12:46:27,197 [MainThread  ] [INFO ]  step 18, loss 0.0374732\n",
      "2017-09-26 12:46:27,216 [MainThread  ] [INFO ]  step 19, loss 0.0640967\n",
      "2017-09-26 12:46:27,234 [MainThread  ] [INFO ]  step 20, loss 0.0338814\n",
      "2017-09-26 12:46:27,254 [MainThread  ] [INFO ]  step 21, loss 0.0373794\n",
      "2017-09-26 12:46:27,363 [MainThread  ] [INFO ]  step 22, loss 0.0252389\n",
      "2017-09-26 12:46:27,382 [MainThread  ] [INFO ]  step 23, loss 0.042003\n",
      "2017-09-26 12:46:27,394 [MainThread  ] [INFO ]  step 24, loss 0.0352994\n",
      "2017-09-26 12:46:27,414 [MainThread  ] [INFO ]  step 25, loss 0.0268939\n",
      "2017-09-26 12:46:27,433 [MainThread  ] [INFO ]  step 26, loss 0.0361597\n",
      "2017-09-26 12:46:27,455 [MainThread  ] [INFO ]  step 27, loss 0.0396787\n",
      "2017-09-26 12:46:27,475 [MainThread  ] [INFO ]  step 28, loss 0.0440256\n",
      "2017-09-26 12:46:27,488 [MainThread  ] [INFO ]  step 29, loss 0.0294912\n",
      "2017-09-26 12:46:27,503 [MainThread  ] [INFO ]  step 30, loss 0.0572421\n",
      "2017-09-26 12:46:27,617 [MainThread  ] [INFO ]  step 31, loss 0.0322215\n",
      "2017-09-26 12:46:27,629 [MainThread  ] [INFO ]  step 32, loss 0.0299562\n",
      "2017-09-26 12:46:27,643 [MainThread  ] [INFO ]  step 33, loss 0.0379703\n",
      "2017-09-26 12:46:27,754 [MainThread  ] [INFO ]  step 34, loss 0.0397513\n",
      "2017-09-26 12:46:27,770 [MainThread  ] [INFO ]  step 35, loss 0.0333984\n",
      "2017-09-26 12:46:27,785 [MainThread  ] [INFO ]  step 36, loss 0.0411304\n",
      "2017-09-26 12:46:27,802 [MainThread  ] [INFO ]  step 37, loss 0.0375645\n",
      "2017-09-26 12:46:27,823 [MainThread  ] [INFO ]  step 38, loss 0.0322807\n",
      "2017-09-26 12:46:27,841 [MainThread  ] [INFO ]  step 39, loss 0.0467361\n",
      "2017-09-26 12:46:27,858 [MainThread  ] [INFO ]  step 40, loss 0.0207883\n",
      "2017-09-26 12:46:27,875 [MainThread  ] [INFO ]  step 41, loss 0.0179469\n",
      "2017-09-26 12:46:27,890 [MainThread  ] [INFO ]  step 42, loss 0.0317354\n",
      "2017-09-26 12:46:27,903 [MainThread  ] [INFO ]  step 43, loss 0.022402\n",
      "2017-09-26 12:46:27,922 [MainThread  ] [INFO ]  step 44, loss 0.0306148\n",
      "2017-09-26 12:46:27,936 [MainThread  ] [INFO ]  step 45, loss 0.0473965\n",
      "2017-09-26 12:46:27,952 [MainThread  ] [INFO ]  step 46, loss 0.030384\n",
      "2017-09-26 12:46:27,966 [MainThread  ] [INFO ]  step 47, loss 0.0186201\n",
      "2017-09-26 12:46:27,982 [MainThread  ] [INFO ]  step 48, loss 0.0603282\n",
      "2017-09-26 12:46:27,998 [MainThread  ] [INFO ]  step 49, loss 0.0283534\n",
      "2017-09-26 12:46:28,017 [MainThread  ] [INFO ]  step 50, loss 0.0529886\n",
      "2017-09-26 12:46:28,031 [MainThread  ] [INFO ]  step 51, loss 0.019869\n",
      "2017-09-26 12:46:28,047 [MainThread  ] [INFO ]  step 52, loss 0.025375\n",
      "2017-09-26 12:46:28,061 [MainThread  ] [INFO ]  step 53, loss 0.0417571\n",
      "2017-09-26 12:46:28,075 [MainThread  ] [INFO ]  step 54, loss 0.0466851\n",
      "2017-09-26 12:46:28,091 [MainThread  ] [INFO ]  step 55, loss 0.0321335\n",
      "2017-09-26 12:46:28,105 [MainThread  ] [INFO ]  step 56, loss 0.0394507\n",
      "2017-09-26 12:46:28,120 [MainThread  ] [INFO ]  step 57, loss 0.0174784\n",
      "2017-09-26 12:46:28,237 [MainThread  ] [INFO ]  step 58, loss 0.0130475\n",
      "2017-09-26 12:46:28,257 [MainThread  ] [INFO ]  step 59, loss 0.0289529\n",
      "2017-09-26 12:46:28,271 [MainThread  ] [INFO ]  step 60, loss 0.0212223\n",
      "2017-09-26 12:46:28,294 [MainThread  ] [INFO ]  step 61, loss 0.039027\n",
      "2017-09-26 12:46:28,312 [MainThread  ] [INFO ]  step 62, loss 0.0277033\n",
      "2017-09-26 12:46:28,328 [MainThread  ] [INFO ]  step 63, loss 0.0512477\n",
      "2017-09-26 12:46:28,347 [MainThread  ] [INFO ]  step 64, loss 0.0168852\n",
      "2017-09-26 12:46:28,472 [MainThread  ] [INFO ]  step 65, loss 0.0251108\n",
      "2017-09-26 12:46:28,487 [MainThread  ] [INFO ]  step 66, loss 0.00732379\n",
      "2017-09-26 12:46:28,505 [MainThread  ] [INFO ]  step 67, loss 0.0382044\n",
      "2017-09-26 12:46:28,519 [MainThread  ] [INFO ]  step 68, loss 0.0192786\n",
      "2017-09-26 12:46:28,535 [MainThread  ] [INFO ]  step 69, loss 0.0242229\n",
      "2017-09-26 12:46:28,553 [MainThread  ] [INFO ]  step 70, loss 0.0157955\n",
      "2017-09-26 12:46:28,570 [MainThread  ] [INFO ]  step 71, loss 0.00693415\n",
      "2017-09-26 12:46:28,584 [MainThread  ] [INFO ]  step 72, loss 0.0282421\n",
      "2017-09-26 12:46:28,599 [MainThread  ] [INFO ]  step 73, loss 0.0170212\n",
      "2017-09-26 12:46:28,615 [MainThread  ] [INFO ]  step 74, loss 0.032423\n",
      "2017-09-26 12:46:28,631 [MainThread  ] [INFO ]  step 75, loss 0.0269679\n",
      "2017-09-26 12:46:28,647 [MainThread  ] [INFO ]  step 76, loss 0.0196299\n",
      "2017-09-26 12:46:28,662 [MainThread  ] [INFO ]  step 77, loss 0.0303289\n",
      "2017-09-26 12:46:28,676 [MainThread  ] [INFO ]  step 78, loss 0.0346777\n",
      "2017-09-26 12:46:28,692 [MainThread  ] [INFO ]  step 79, loss 0.0334943\n",
      "2017-09-26 12:46:28,803 [MainThread  ] [INFO ]  step 80, loss 0.030024\n",
      "2017-09-26 12:46:28,815 [MainThread  ] [INFO ]  step 81, loss 0.0216424\n",
      "2017-09-26 12:46:28,836 [MainThread  ] [INFO ]  step 82, loss 0.0374445\n",
      "2017-09-26 12:46:28,852 [MainThread  ] [INFO ]  step 83, loss 0.040617\n",
      "2017-09-26 12:46:28,866 [MainThread  ] [INFO ]  step 84, loss 0.0144432\n",
      "2017-09-26 12:46:28,884 [MainThread  ] [INFO ]  step 85, loss 0.0294754\n",
      "2017-09-26 12:46:28,898 [MainThread  ] [INFO ]  step 86, loss 0.0392253\n",
      "2017-09-26 12:46:28,913 [MainThread  ] [INFO ]  step 87, loss 0.0228827\n",
      "2017-09-26 12:46:28,929 [MainThread  ] [INFO ]  step 88, loss 0.0280889\n",
      "2017-09-26 12:46:29,039 [MainThread  ] [INFO ]  step 89, loss 0.0378388\n",
      "2017-09-26 12:46:29,059 [MainThread  ] [INFO ]  step 90, loss 0.0213032\n",
      "2017-09-26 12:46:29,081 [MainThread  ] [INFO ]  step 91, loss 0.0114087\n",
      "2017-09-26 12:46:29,097 [MainThread  ] [INFO ]  step 92, loss 0.023233\n",
      "2017-09-26 12:46:29,111 [MainThread  ] [INFO ]  step 93, loss 0.019594\n",
      "2017-09-26 12:46:29,125 [MainThread  ] [INFO ]  step 94, loss 0.0292507\n",
      "2017-09-26 12:46:29,139 [MainThread  ] [INFO ]  step 95, loss 0.0354758\n",
      "2017-09-26 12:46:29,153 [MainThread  ] [INFO ]  step 96, loss 0.0291173\n",
      "2017-09-26 12:46:29,165 [MainThread  ] [INFO ]  step 97, loss 0.0190365\n",
      "2017-09-26 12:46:29,179 [MainThread  ] [INFO ]  step 98, loss 0.0256355\n",
      "2017-09-26 12:46:29,192 [MainThread  ] [INFO ]  step 99, loss 0.040216\n",
      "2017-09-26 12:46:29,301 [MainThread  ] [INFO ]  step 100, loss 0.0032564\n",
      "2017-09-26 12:46:29,313 [MainThread  ] [INFO ]  step 101, loss 0.0330344\n",
      "2017-09-26 12:46:29,327 [MainThread  ] [INFO ]  step 102, loss 0.0136831\n",
      "2017-09-26 12:46:29,345 [MainThread  ] [INFO ]  step 103, loss 0.0297058\n",
      "2017-09-26 12:46:29,358 [MainThread  ] [INFO ]  step 104, loss 0.0340973\n",
      "2017-09-26 12:46:29,372 [MainThread  ] [INFO ]  step 105, loss 0.0248975\n",
      "2017-09-26 12:46:29,386 [MainThread  ] [INFO ]  step 106, loss 0.0204059\n",
      "2017-09-26 12:46:29,401 [MainThread  ] [INFO ]  step 107, loss 0.0213297\n",
      "2017-09-26 12:46:29,416 [MainThread  ] [INFO ]  step 108, loss 0.0101447\n",
      "2017-09-26 12:46:29,428 [MainThread  ] [INFO ]  step 109, loss 0.0389518\n",
      "2017-09-26 12:46:29,444 [MainThread  ] [INFO ]  step 110, loss 0.00968609\n",
      "2017-09-26 12:46:29,459 [MainThread  ] [INFO ]  step 111, loss 0.0140128\n",
      "2017-09-26 12:46:29,475 [MainThread  ] [INFO ]  step 112, loss 0.0102353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-26 12:46:29,491 [MainThread  ] [INFO ]  step 113, loss 0.0184822\n",
      "2017-09-26 12:46:29,506 [MainThread  ] [INFO ]  step 114, loss 0.0278372\n",
      "2017-09-26 12:46:29,520 [MainThread  ] [INFO ]  step 115, loss 0.00628317\n",
      "2017-09-26 12:46:29,534 [MainThread  ] [INFO ]  step 116, loss 0.0225291\n",
      "2017-09-26 12:46:29,546 [MainThread  ] [INFO ]  step 117, loss 0.0145395\n",
      "2017-09-26 12:46:29,560 [MainThread  ] [INFO ]  step 118, loss 0.0307156\n",
      "2017-09-26 12:46:29,665 [MainThread  ] [INFO ]  step 119, loss 0.0322414\n",
      "2017-09-26 12:46:29,682 [MainThread  ] [INFO ]  step 120, loss 0.0119007\n",
      "2017-09-26 12:46:29,698 [MainThread  ] [INFO ]  step 121, loss 0.0134013\n",
      "2017-09-26 12:46:29,712 [MainThread  ] [INFO ]  step 122, loss 0.0197086\n",
      "2017-09-26 12:46:29,724 [MainThread  ] [INFO ]  step 123, loss 0.0121345\n",
      "2017-09-26 12:46:29,738 [MainThread  ] [INFO ]  step 124, loss 0.0123139\n",
      "2017-09-26 12:46:29,751 [MainThread  ] [INFO ]  step 125, loss 0.0265566\n",
      "2017-09-26 12:46:29,765 [MainThread  ] [INFO ]  step 126, loss 0.0249821\n",
      "2017-09-26 12:46:29,778 [MainThread  ] [INFO ]  step 127, loss 0.0340094\n",
      "2017-09-26 12:46:29,791 [MainThread  ] [INFO ]  step 128, loss 0.0257613\n",
      "2017-09-26 12:46:29,806 [MainThread  ] [INFO ]  step 129, loss 0.0146166\n",
      "2017-09-26 12:46:29,819 [MainThread  ] [INFO ]  step 130, loss 0.0191017\n",
      "2017-09-26 12:46:29,832 [MainThread  ] [INFO ]  step 131, loss 0.0145203\n",
      "2017-09-26 12:46:29,846 [MainThread  ] [INFO ]  step 132, loss 0.0383469\n",
      "2017-09-26 12:46:29,858 [MainThread  ] [INFO ]  step 133, loss 0.0338529\n",
      "2017-09-26 12:46:29,874 [MainThread  ] [INFO ]  step 134, loss 0.014279\n",
      "2017-09-26 12:46:29,888 [MainThread  ] [INFO ]  step 135, loss 0.026193\n",
      "2017-09-26 12:46:29,902 [MainThread  ] [INFO ]  step 136, loss 0.0226583\n",
      "2017-09-26 12:46:30,015 [MainThread  ] [INFO ]  step 137, loss 0.0153806\n",
      "2017-09-26 12:46:30,028 [MainThread  ] [INFO ]  step 138, loss 0.0159872\n",
      "2017-09-26 12:46:30,041 [MainThread  ] [INFO ]  step 139, loss 0.0326611\n",
      "2017-09-26 12:46:30,149 [MainThread  ] [INFO ]  step 140, loss 0.0247327\n",
      "2017-09-26 12:46:30,163 [MainThread  ] [INFO ]  step 141, loss 0.0107961\n",
      "2017-09-26 12:46:30,176 [MainThread  ] [INFO ]  step 142, loss 0.0116741\n",
      "2017-09-26 12:46:30,190 [MainThread  ] [INFO ]  step 143, loss 0.0235392\n",
      "2017-09-26 12:46:30,202 [MainThread  ] [INFO ]  step 144, loss 0.0228931\n",
      "2017-09-26 12:46:30,216 [MainThread  ] [INFO ]  step 145, loss 0.0351168\n",
      "2017-09-26 12:46:30,230 [MainThread  ] [INFO ]  step 146, loss 0.0200022\n",
      "2017-09-26 12:46:30,243 [MainThread  ] [INFO ]  step 147, loss 0.0102211\n",
      "2017-09-26 12:46:30,258 [MainThread  ] [INFO ]  step 148, loss 0.0533488\n",
      "2017-09-26 12:46:30,271 [MainThread  ] [INFO ]  step 149, loss 0.0190113\n",
      "2017-09-26 12:46:30,285 [MainThread  ] [INFO ]  step 150, loss 0.04008\n",
      "2017-09-26 12:46:30,298 [MainThread  ] [INFO ]  step 151, loss 0.024297\n",
      "2017-09-26 12:46:30,402 [MainThread  ] [INFO ]  step 152, loss 0.0205997\n",
      "2017-09-26 12:46:30,423 [MainThread  ] [INFO ]  step 153, loss 0.00696144\n",
      "2017-09-26 12:46:30,446 [MainThread  ] [INFO ]  step 154, loss 0.00780351\n",
      "2017-09-26 12:46:30,463 [MainThread  ] [INFO ]  step 155, loss 0.0284052\n",
      "2017-09-26 12:46:30,477 [MainThread  ] [INFO ]  step 156, loss 0.0209902\n",
      "2017-09-26 12:46:30,491 [MainThread  ] [INFO ]  step 157, loss 0.0134198\n",
      "2017-09-26 12:46:30,504 [MainThread  ] [INFO ]  step 158, loss 0.036154\n",
      "2017-09-26 12:46:30,518 [MainThread  ] [INFO ]  step 159, loss 0.00895346\n",
      "2017-09-26 12:46:30,529 [MainThread  ] [INFO ]  step 160, loss 0.0217272\n",
      "2017-09-26 12:46:30,543 [MainThread  ] [INFO ]  step 161, loss 0.0208174\n",
      "2017-09-26 12:46:30,647 [MainThread  ] [INFO ]  step 162, loss 0.0124468\n",
      "2017-09-26 12:46:30,667 [MainThread  ] [INFO ]  step 163, loss 0.00984354\n",
      "2017-09-26 12:46:30,685 [MainThread  ] [INFO ]  step 164, loss 0.0432019\n",
      "2017-09-26 12:46:30,700 [MainThread  ] [INFO ]  step 165, loss 0.0174818\n",
      "2017-09-26 12:46:30,804 [MainThread  ] [INFO ]  step 166, loss 0.0269678\n",
      "2017-09-26 12:46:30,825 [MainThread  ] [INFO ]  step 167, loss 0.0224065\n",
      "2017-09-26 12:46:30,839 [MainThread  ] [INFO ]  step 168, loss 0.0156678\n",
      "2017-09-26 12:46:30,852 [MainThread  ] [INFO ]  step 169, loss 0.0455438\n",
      "2017-09-26 12:46:30,866 [MainThread  ] [INFO ]  step 170, loss 0.00886247\n",
      "2017-09-26 12:46:30,880 [MainThread  ] [INFO ]  step 171, loss 0.0189499\n",
      "2017-09-26 12:46:30,893 [MainThread  ] [INFO ]  step 172, loss 0.0206505\n",
      "2017-09-26 12:46:30,908 [MainThread  ] [INFO ]  step 173, loss 0.0128415\n",
      "2017-09-26 12:46:30,923 [MainThread  ] [INFO ]  step 174, loss 0.0251304\n",
      "2017-09-26 12:46:30,937 [MainThread  ] [INFO ]  step 175, loss 0.0124755\n",
      "2017-09-26 12:46:30,951 [MainThread  ] [INFO ]  step 176, loss 0.0129565\n",
      "2017-09-26 12:46:30,970 [MainThread  ] [INFO ]  step 177, loss 0.0164326\n",
      "2017-09-26 12:46:30,986 [MainThread  ] [INFO ]  step 178, loss 0.0108337\n",
      "2017-09-26 12:46:30,999 [MainThread  ] [INFO ]  step 179, loss 0.0148621\n",
      "2017-09-26 12:46:31,018 [MainThread  ] [INFO ]  step 180, loss 0.0107334\n",
      "2017-09-26 12:46:31,033 [MainThread  ] [INFO ]  step 181, loss 0.0178416\n",
      "2017-09-26 12:46:31,053 [MainThread  ] [INFO ]  step 182, loss 0.0451366\n",
      "2017-09-26 12:46:31,068 [MainThread  ] [INFO ]  step 183, loss 0.00457403\n",
      "2017-09-26 12:46:31,081 [MainThread  ] [INFO ]  step 184, loss 0.0292472\n",
      "2017-09-26 12:46:31,192 [MainThread  ] [INFO ]  step 185, loss 0.0249761\n",
      "2017-09-26 12:46:31,212 [MainThread  ] [INFO ]  step 186, loss 0.0184234\n",
      "2017-09-26 12:46:31,228 [MainThread  ] [INFO ]  step 187, loss 0.0220594\n",
      "2017-09-26 12:46:31,242 [MainThread  ] [INFO ]  step 188, loss 0.0203226\n",
      "2017-09-26 12:46:31,257 [MainThread  ] [INFO ]  step 189, loss 0.0166457\n",
      "2017-09-26 12:46:31,271 [MainThread  ] [INFO ]  step 190, loss 0.0172193\n",
      "2017-09-26 12:46:31,286 [MainThread  ] [INFO ]  step 191, loss 0.0163062\n",
      "2017-09-26 12:46:31,303 [MainThread  ] [INFO ]  step 192, loss 0.010936\n",
      "2017-09-26 12:46:31,318 [MainThread  ] [INFO ]  step 193, loss 0.023918\n",
      "2017-09-26 12:46:31,332 [MainThread  ] [INFO ]  step 194, loss 0.0013015\n",
      "2017-09-26 12:46:31,347 [MainThread  ] [INFO ]  step 195, loss 0.00907296\n",
      "2017-09-26 12:46:31,360 [MainThread  ] [INFO ]  step 196, loss 0.0176233\n",
      "2017-09-26 12:46:31,376 [MainThread  ] [INFO ]  step 197, loss 0.0168459\n",
      "2017-09-26 12:46:31,390 [MainThread  ] [INFO ]  step 198, loss 0.00807787\n",
      "2017-09-26 12:46:31,407 [MainThread  ] [INFO ]  step 199, loss 0.0068503\n",
      "2017-09-26 12:46:31,423 [MainThread  ] [INFO ]  step 200, loss 0.0219917\n",
      "2017-09-26 12:46:31,439 [MainThread  ] [INFO ]  step 201, loss 0.0161647\n",
      "2017-09-26 12:46:31,455 [MainThread  ] [INFO ]  step 202, loss 0.0402032\n",
      "2017-09-26 12:46:31,470 [MainThread  ] [INFO ]  step 203, loss 0.0174261\n",
      "2017-09-26 12:46:31,489 [MainThread  ] [INFO ]  step 204, loss 0.0200141\n",
      "2017-09-26 12:46:31,502 [MainThread  ] [INFO ]  step 205, loss 0.0229891\n",
      "2017-09-26 12:46:31,516 [MainThread  ] [INFO ]  step 206, loss 0.0216069\n",
      "2017-09-26 12:46:31,529 [MainThread  ] [INFO ]  step 207, loss 0.00724022\n",
      "2017-09-26 12:46:31,545 [MainThread  ] [INFO ]  step 208, loss 0.0129458\n",
      "2017-09-26 12:46:31,559 [MainThread  ] [INFO ]  step 209, loss 0.0157884\n",
      "2017-09-26 12:46:31,575 [MainThread  ] [INFO ]  step 210, loss 0.00415919\n",
      "2017-09-26 12:46:31,589 [MainThread  ] [INFO ]  step 211, loss 0.0261288\n",
      "2017-09-26 12:46:31,697 [MainThread  ] [INFO ]  step 212, loss 0.0302783\n",
      "2017-09-26 12:46:31,711 [MainThread  ] [INFO ]  step 213, loss 0.00798481\n",
      "2017-09-26 12:46:31,724 [MainThread  ] [INFO ]  step 214, loss 0.0295752\n",
      "2017-09-26 12:46:31,737 [MainThread  ] [INFO ]  step 215, loss 0.0121341\n",
      "2017-09-26 12:46:31,755 [MainThread  ] [INFO ]  step 216, loss 0.0077355\n",
      "2017-09-26 12:46:31,768 [MainThread  ] [INFO ]  step 217, loss 0.0112272\n",
      "2017-09-26 12:46:31,781 [MainThread  ] [INFO ]  step 218, loss 0.0352949\n",
      "2017-09-26 12:46:31,793 [MainThread  ] [INFO ]  step 219, loss 0.0076524\n",
      "2017-09-26 12:46:31,811 [MainThread  ] [INFO ]  step 220, loss 0.0251204\n",
      "2017-09-26 12:46:31,825 [MainThread  ] [INFO ]  step 221, loss 0.0122153\n",
      "2017-09-26 12:46:31,843 [MainThread  ] [INFO ]  step 222, loss 0.00897987\n",
      "2017-09-26 12:46:31,947 [MainThread  ] [INFO ]  step 223, loss 0.00486183\n",
      "2017-09-26 12:46:31,967 [MainThread  ] [INFO ]  step 224, loss 0.0240207\n",
      "2017-09-26 12:46:31,984 [MainThread  ] [INFO ]  step 225, loss 0.0281048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-26 12:46:32,005 [MainThread  ] [INFO ]  step 226, loss 0.0120292\n",
      "2017-09-26 12:46:32,022 [MainThread  ] [INFO ]  step 227, loss 0.00739951\n",
      "2017-09-26 12:46:32,039 [MainThread  ] [INFO ]  step 228, loss 0.00624196\n",
      "2017-09-26 12:46:32,056 [MainThread  ] [INFO ]  step 229, loss 0.0104164\n",
      "2017-09-26 12:46:32,070 [MainThread  ] [INFO ]  step 230, loss 0.00424813\n",
      "2017-09-26 12:46:32,085 [MainThread  ] [INFO ]  step 231, loss 0.00422698\n",
      "2017-09-26 12:46:32,103 [MainThread  ] [INFO ]  step 232, loss 0.0273323\n",
      "2017-09-26 12:46:32,116 [MainThread  ] [INFO ]  step 233, loss 0.0042448\n",
      "2017-09-26 12:46:32,133 [MainThread  ] [INFO ]  step 234, loss 0.0154201\n",
      "2017-09-26 12:46:32,149 [MainThread  ] [INFO ]  step 235, loss 0.00141191\n",
      "2017-09-26 12:46:32,162 [MainThread  ] [INFO ]  step 236, loss 0.0103044\n",
      "2017-09-26 12:46:32,175 [MainThread  ] [INFO ]  step 237, loss 0.00887779\n",
      "2017-09-26 12:46:32,278 [MainThread  ] [INFO ]  step 238, loss 0.00971642\n",
      "2017-09-26 12:46:32,298 [MainThread  ] [INFO ]  step 239, loss 0.0314986\n",
      "2017-09-26 12:46:32,309 [MainThread  ] [INFO ]  step 240, loss 0.0134257\n",
      "2017-09-26 12:46:32,421 [MainThread  ] [INFO ]  step 241, loss 0.00552683\n",
      "2017-09-26 12:46:32,523 [MainThread  ] [INFO ]  step 242, loss 0.00351165\n",
      "2017-09-26 12:46:32,541 [MainThread  ] [INFO ]  step 243, loss 0.00304054\n",
      "2017-09-26 12:46:32,559 [MainThread  ] [INFO ]  step 244, loss 0.0161782\n",
      "2017-09-26 12:46:32,575 [MainThread  ] [INFO ]  step 245, loss 0.00798151\n",
      "2017-09-26 12:46:32,593 [MainThread  ] [INFO ]  step 246, loss 0.0257202\n",
      "2017-09-26 12:46:32,611 [MainThread  ] [INFO ]  step 247, loss 0.0184389\n",
      "2017-09-26 12:46:32,624 [MainThread  ] [INFO ]  step 248, loss 0.0108362\n",
      "2017-09-26 12:46:32,638 [MainThread  ] [INFO ]  step 249, loss 0.00523594\n",
      "2017-09-26 12:46:32,651 [MainThread  ] [INFO ]  step 250, loss 0.0107921\n",
      "2017-09-26 12:46:32,664 [MainThread  ] [INFO ]  step 251, loss 0.0337758\n",
      "2017-09-26 12:46:32,678 [MainThread  ] [INFO ]  step 252, loss 0.0184784\n",
      "2017-09-26 12:46:32,696 [MainThread  ] [INFO ]  step 253, loss 0.00326988\n",
      "2017-09-26 12:46:32,708 [MainThread  ] [INFO ]  step 254, loss 0.0263204\n",
      "2017-09-26 12:46:32,720 [MainThread  ] [INFO ]  step 255, loss 0.0113941\n",
      "2017-09-26 12:46:32,734 [MainThread  ] [INFO ]  step 256, loss 0.0299738\n",
      "2017-09-26 12:46:32,749 [MainThread  ] [INFO ]  step 257, loss 0.0205151\n",
      "2017-09-26 12:46:32,763 [MainThread  ] [INFO ]  step 258, loss 0.0204449\n",
      "2017-09-26 12:46:32,778 [MainThread  ] [INFO ]  step 259, loss 0.0157104\n",
      "2017-09-26 12:46:32,795 [MainThread  ] [INFO ]  step 260, loss 0.0207065\n",
      "2017-09-26 12:46:32,807 [MainThread  ] [INFO ]  step 261, loss 0.00921401\n",
      "2017-09-26 12:46:32,820 [MainThread  ] [INFO ]  step 262, loss 0.0079585\n",
      "2017-09-26 12:46:32,833 [MainThread  ] [INFO ]  step 263, loss 0.0164461\n",
      "2017-09-26 12:46:32,851 [MainThread  ] [INFO ]  step 264, loss 0.0146364\n",
      "2017-09-26 12:46:32,864 [MainThread  ] [INFO ]  step 265, loss 0.00596077\n",
      "2017-09-26 12:46:32,878 [MainThread  ] [INFO ]  step 266, loss 0.0214265\n",
      "2017-09-26 12:46:32,894 [MainThread  ] [INFO ]  step 267, loss 0.012041\n",
      "2017-09-26 12:46:32,909 [MainThread  ] [INFO ]  step 268, loss 0.0197421\n",
      "2017-09-26 12:46:32,923 [MainThread  ] [INFO ]  step 269, loss 0.0163909\n",
      "2017-09-26 12:46:32,938 [MainThread  ] [INFO ]  step 270, loss 0.0132526\n",
      "2017-09-26 12:46:32,951 [MainThread  ] [INFO ]  step 271, loss 0.0031372\n",
      "2017-09-26 12:46:32,964 [MainThread  ] [INFO ]  step 272, loss 0.0189185\n",
      "2017-09-26 12:46:32,980 [MainThread  ] [INFO ]  step 273, loss 0.00911566\n",
      "2017-09-26 12:46:32,992 [MainThread  ] [INFO ]  step 274, loss 0.0164657\n",
      "2017-09-26 12:46:33,006 [MainThread  ] [INFO ]  step 275, loss 0.0122402\n",
      "2017-09-26 12:46:33,019 [MainThread  ] [INFO ]  step 276, loss 0.0126187\n",
      "2017-09-26 12:46:33,032 [MainThread  ] [INFO ]  step 277, loss 0.0191045\n",
      "2017-09-26 12:46:33,053 [MainThread  ] [INFO ]  step 278, loss 0.0142935\n",
      "2017-09-26 12:46:33,066 [MainThread  ] [INFO ]  step 279, loss 0.00692077\n",
      "2017-09-26 12:46:33,079 [MainThread  ] [INFO ]  step 280, loss 0.0188705\n",
      "2017-09-26 12:46:33,095 [MainThread  ] [INFO ]  step 281, loss 0.00263988\n",
      "2017-09-26 12:46:33,108 [MainThread  ] [INFO ]  step 282, loss 0.0166501\n",
      "2017-09-26 12:46:33,121 [MainThread  ] [INFO ]  step 283, loss 0.0155021\n",
      "2017-09-26 12:46:33,223 [MainThread  ] [INFO ]  step 284, loss 0.0137298\n",
      "2017-09-26 12:46:33,242 [MainThread  ] [INFO ]  step 285, loss 0.0110735\n",
      "2017-09-26 12:46:33,259 [MainThread  ] [INFO ]  step 286, loss 0.00297875\n",
      "2017-09-26 12:46:33,276 [MainThread  ] [INFO ]  step 287, loss 0.00667259\n",
      "2017-09-26 12:46:33,293 [MainThread  ] [INFO ]  step 288, loss 0.00153667\n",
      "2017-09-26 12:46:33,306 [MainThread  ] [INFO ]  step 289, loss 0.0146887\n",
      "2017-09-26 12:46:33,319 [MainThread  ] [INFO ]  step 290, loss 0.0160194\n",
      "2017-09-26 12:46:33,332 [MainThread  ] [INFO ]  step 291, loss 0.0298362\n",
      "2017-09-26 12:46:33,345 [MainThread  ] [INFO ]  step 292, loss 0.017703\n",
      "2017-09-26 12:46:33,451 [MainThread  ] [INFO ]  step 293, loss 0.0132354\n",
      "2017-09-26 12:46:33,465 [MainThread  ] [INFO ]  step 294, loss 0.0145126\n",
      "2017-09-26 12:46:33,477 [MainThread  ] [INFO ]  step 295, loss 0.00734379\n",
      "2017-09-26 12:46:33,490 [MainThread  ] [INFO ]  step 296, loss 0.0241544\n",
      "2017-09-26 12:46:33,504 [MainThread  ] [INFO ]  step 297, loss 0.0160087\n",
      "2017-09-26 12:46:33,521 [MainThread  ] [INFO ]  step 298, loss 0.0311661\n",
      "2017-09-26 12:46:33,535 [MainThread  ] [INFO ]  step 299, loss 0.0167758\n",
      "2017-09-26 12:46:33,549 [MainThread  ] [INFO ]  step 300, loss 0.00946059\n",
      "2017-09-26 12:46:33,565 [MainThread  ] [INFO ]  step 301, loss 0.0172893\n",
      "2017-09-26 12:46:33,576 [MainThread  ] [INFO ]  step 302, loss 0.0361168\n",
      "2017-09-26 12:46:33,592 [MainThread  ] [INFO ]  step 303, loss 0.0161291\n",
      "2017-09-26 12:46:33,607 [MainThread  ] [INFO ]  step 304, loss 0.00383199\n",
      "2017-09-26 12:46:33,622 [MainThread  ] [INFO ]  step 305, loss 0.00897286\n",
      "2017-09-26 12:46:33,635 [MainThread  ] [INFO ]  step 306, loss 0.0169392\n",
      "2017-09-26 12:46:33,647 [MainThread  ] [INFO ]  step 307, loss 0.0325444\n",
      "2017-09-26 12:46:33,662 [MainThread  ] [INFO ]  step 308, loss 0.0160909\n",
      "2017-09-26 12:46:33,677 [MainThread  ] [INFO ]  step 309, loss 0.0286662\n",
      "2017-09-26 12:46:33,690 [MainThread  ] [INFO ]  step 310, loss 0.0119469\n",
      "2017-09-26 12:46:33,710 [MainThread  ] [INFO ]  step 311, loss 0.0062078\n",
      "2017-09-26 12:46:33,727 [MainThread  ] [INFO ]  step 312, loss 0.0021791\n",
      "2017-09-26 12:46:33,742 [MainThread  ] [INFO ]  step 313, loss 0.0076823\n",
      "2017-09-26 12:46:33,757 [MainThread  ] [INFO ]  step 314, loss 0.00694886\n",
      "2017-09-26 12:46:33,773 [MainThread  ] [INFO ]  step 315, loss 0.0152164\n",
      "2017-09-26 12:46:33,786 [MainThread  ] [INFO ]  step 316, loss 0.00731371\n",
      "2017-09-26 12:46:33,899 [MainThread  ] [INFO ]  step 317, loss 0.013241\n",
      "2017-09-26 12:46:33,918 [MainThread  ] [INFO ]  step 318, loss 0.0239251\n",
      "2017-09-26 12:46:33,938 [MainThread  ] [INFO ]  step 319, loss 0.00552294\n",
      "2017-09-26 12:46:33,951 [MainThread  ] [INFO ]  step 320, loss 0.0210972\n",
      "2017-09-26 12:46:33,964 [MainThread  ] [INFO ]  step 321, loss 0.0191553\n",
      "2017-09-26 12:46:33,979 [MainThread  ] [INFO ]  step 322, loss 0.00761135\n",
      "2017-09-26 12:46:33,992 [MainThread  ] [INFO ]  step 323, loss 0.0195488\n",
      "2017-09-26 12:46:34,012 [MainThread  ] [INFO ]  step 324, loss 0.0207624\n",
      "2017-09-26 12:46:34,024 [MainThread  ] [INFO ]  step 325, loss 0.0133105\n",
      "2017-09-26 12:46:34,041 [MainThread  ] [INFO ]  step 326, loss 0.0126821\n",
      "2017-09-26 12:46:34,057 [MainThread  ] [INFO ]  step 327, loss 0.0125692\n",
      "2017-09-26 12:46:34,071 [MainThread  ] [INFO ]  step 328, loss 0.0111\n",
      "2017-09-26 12:46:34,088 [MainThread  ] [INFO ]  step 329, loss 0.0124031\n",
      "2017-09-26 12:46:34,102 [MainThread  ] [INFO ]  step 330, loss 0.0287001\n",
      "2017-09-26 12:46:34,116 [MainThread  ] [INFO ]  step 331, loss 0.00839805\n",
      "2017-09-26 12:46:34,130 [MainThread  ] [INFO ]  step 332, loss 0.0233143\n",
      "2017-09-26 12:46:34,144 [MainThread  ] [INFO ]  step 333, loss 0.0164609\n",
      "2017-09-26 12:46:34,160 [MainThread  ] [INFO ]  step 334, loss 0.0133361\n",
      "2017-09-26 12:46:34,174 [MainThread  ] [INFO ]  step 335, loss 0.00845482\n",
      "2017-09-26 12:46:34,277 [MainThread  ] [INFO ]  step 336, loss 0.00706435\n",
      "2017-09-26 12:46:34,300 [MainThread  ] [INFO ]  step 337, loss 0.0231052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-26 12:46:34,316 [MainThread  ] [INFO ]  step 338, loss 0.0148824\n",
      "2017-09-26 12:46:34,328 [MainThread  ] [INFO ]  step 339, loss 0.0149038\n",
      "2017-09-26 12:46:34,342 [MainThread  ] [INFO ]  step 340, loss 0.00738497\n",
      "2017-09-26 12:46:34,359 [MainThread  ] [INFO ]  step 341, loss 0.00463407\n",
      "2017-09-26 12:46:34,372 [MainThread  ] [INFO ]  step 342, loss 0.0172952\n",
      "2017-09-26 12:46:34,384 [MainThread  ] [INFO ]  step 343, loss 0.0110016\n",
      "2017-09-26 12:46:34,397 [MainThread  ] [INFO ]  step 344, loss 0.0212926\n",
      "2017-09-26 12:46:34,410 [MainThread  ] [INFO ]  step 345, loss 0.0101907\n",
      "2017-09-26 12:46:34,424 [MainThread  ] [INFO ]  step 346, loss 0.0185387\n",
      "2017-09-26 12:46:34,438 [MainThread  ] [INFO ]  step 347, loss 0.0187736\n",
      "2017-09-26 12:46:34,451 [MainThread  ] [INFO ]  step 348, loss 0.0191992\n",
      "2017-09-26 12:46:34,466 [MainThread  ] [INFO ]  step 349, loss 0.00538225\n",
      "2017-09-26 12:46:34,478 [MainThread  ] [INFO ]  step 350, loss 0.0317709\n",
      "2017-09-26 12:46:34,582 [MainThread  ] [INFO ]  step 351, loss 0.0162391\n",
      "2017-09-26 12:46:34,596 [MainThread  ] [INFO ]  step 352, loss 0.0176206\n",
      "2017-09-26 12:46:34,612 [MainThread  ] [INFO ]  step 353, loss 0.0111805\n",
      "2017-09-26 12:46:34,624 [MainThread  ] [INFO ]  step 354, loss 0.0017237\n",
      "2017-09-26 12:46:34,638 [MainThread  ] [INFO ]  step 355, loss 0.00358711\n",
      "2017-09-26 12:46:34,652 [MainThread  ] [INFO ]  step 356, loss 0.0213605\n",
      "2017-09-26 12:46:34,669 [MainThread  ] [INFO ]  step 357, loss 0.0201233\n",
      "2017-09-26 12:46:34,683 [MainThread  ] [INFO ]  step 358, loss 0.0116438\n",
      "2017-09-26 12:46:34,696 [MainThread  ] [INFO ]  step 359, loss 0.00504449\n",
      "2017-09-26 12:46:34,708 [MainThread  ] [INFO ]  step 360, loss 0.00694166\n",
      "2017-09-26 12:46:34,721 [MainThread  ] [INFO ]  step 361, loss 0.0142038\n",
      "2017-09-26 12:46:34,734 [MainThread  ] [INFO ]  step 362, loss 0.0190252\n",
      "2017-09-26 12:46:34,837 [MainThread  ] [INFO ]  step 363, loss 0.023156\n",
      "2017-09-26 12:46:34,856 [MainThread  ] [INFO ]  step 364, loss 0.00256553\n",
      "2017-09-26 12:46:34,878 [MainThread  ] [INFO ]  step 365, loss 0.0069811\n",
      "2017-09-26 12:46:34,987 [MainThread  ] [INFO ]  step 366, loss 0.00293134\n",
      "2017-09-26 12:46:35,003 [MainThread  ] [INFO ]  step 367, loss 0.0137074\n",
      "2017-09-26 12:46:35,015 [MainThread  ] [INFO ]  step 368, loss 0.0129768\n",
      "2017-09-26 12:46:35,028 [MainThread  ] [INFO ]  step 369, loss 0.00826528\n",
      "2017-09-26 12:46:35,041 [MainThread  ] [INFO ]  step 370, loss 0.0188279\n",
      "2017-09-26 12:46:35,058 [MainThread  ] [INFO ]  step 371, loss 0.00317906\n",
      "2017-09-26 12:46:35,071 [MainThread  ] [INFO ]  step 372, loss 0.0138638\n",
      "2017-09-26 12:46:35,084 [MainThread  ] [INFO ]  step 373, loss 0.0388485\n",
      "2017-09-26 12:46:35,097 [MainThread  ] [INFO ]  step 374, loss 0.0249128\n",
      "2017-09-26 12:46:35,111 [MainThread  ] [INFO ]  step 375, loss 0.0176784\n",
      "2017-09-26 12:46:35,124 [MainThread  ] [INFO ]  step 376, loss 0.0223855\n",
      "2017-09-26 12:46:35,137 [MainThread  ] [INFO ]  step 377, loss 0.00692088\n",
      "2017-09-26 12:46:35,152 [MainThread  ] [INFO ]  step 378, loss 0.00935351\n",
      "2017-09-26 12:46:35,171 [MainThread  ] [INFO ]  step 379, loss 0.0228737\n",
      "2017-09-26 12:46:35,184 [MainThread  ] [INFO ]  step 380, loss 0.0\n",
      "2017-09-26 12:46:35,199 [MainThread  ] [INFO ]  step 381, loss 0.0131888\n",
      "2017-09-26 12:46:35,216 [MainThread  ] [INFO ]  step 382, loss 0.00908262\n",
      "2017-09-26 12:46:35,231 [MainThread  ] [INFO ]  step 383, loss 0.0144625\n",
      "2017-09-26 12:46:35,246 [MainThread  ] [INFO ]  step 384, loss 0.0058854\n",
      "2017-09-26 12:46:35,260 [MainThread  ] [INFO ]  step 385, loss 0.0250032\n",
      "2017-09-26 12:46:35,276 [MainThread  ] [INFO ]  step 386, loss 0.00408602\n",
      "2017-09-26 12:46:35,291 [MainThread  ] [INFO ]  step 387, loss 0.0242482\n",
      "2017-09-26 12:46:35,306 [MainThread  ] [INFO ]  step 388, loss 0.00600956\n",
      "2017-09-26 12:46:35,320 [MainThread  ] [INFO ]  step 389, loss 0.027931\n",
      "2017-09-26 12:46:35,335 [MainThread  ] [INFO ]  step 390, loss 0.00636533\n",
      "2017-09-26 12:46:35,349 [MainThread  ] [INFO ]  step 391, loss 0.00202121\n",
      "2017-09-26 12:46:35,363 [MainThread  ] [INFO ]  step 392, loss 0.00718658\n",
      "2017-09-26 12:46:35,380 [MainThread  ] [INFO ]  step 393, loss 0.0295084\n",
      "2017-09-26 12:46:35,492 [MainThread  ] [INFO ]  step 394, loss 0.00667383\n",
      "2017-09-26 12:46:35,506 [MainThread  ] [INFO ]  step 395, loss 0.0247295\n",
      "2017-09-26 12:46:35,522 [MainThread  ] [INFO ]  step 396, loss 0.00805758\n",
      "2017-09-26 12:46:35,542 [MainThread  ] [INFO ]  step 397, loss 0.0130917\n",
      "2017-09-26 12:46:35,557 [MainThread  ] [INFO ]  step 398, loss 0.0240007\n",
      "2017-09-26 12:46:35,578 [MainThread  ] [INFO ]  step 399, loss 0.00617219\n",
      "2017-09-26 12:46:35,597 [MainThread  ] [INFO ]  step 400, loss 0.0159408\n",
      "2017-09-26 12:46:35,616 [MainThread  ] [INFO ]  step 401, loss 0.0126779\n",
      "2017-09-26 12:46:35,629 [MainThread  ] [INFO ]  step 402, loss 0.0059299\n",
      "2017-09-26 12:46:35,641 [MainThread  ] [INFO ]  step 403, loss 0.0301224\n",
      "2017-09-26 12:46:35,658 [MainThread  ] [INFO ]  step 404, loss 0.0138587\n",
      "2017-09-26 12:46:35,765 [MainThread  ] [INFO ]  step 405, loss 0.0255091\n",
      "2017-09-26 12:46:35,784 [MainThread  ] [INFO ]  step 406, loss 0.00723032\n",
      "2017-09-26 12:46:35,798 [MainThread  ] [INFO ]  step 407, loss 0.0195916\n",
      "2017-09-26 12:46:35,810 [MainThread  ] [INFO ]  step 408, loss 0.0127173\n",
      "2017-09-26 12:46:35,825 [MainThread  ] [INFO ]  step 409, loss 0.0269371\n",
      "2017-09-26 12:46:35,839 [MainThread  ] [INFO ]  step 410, loss 0.00327646\n",
      "2017-09-26 12:46:35,947 [MainThread  ] [INFO ]  step 411, loss 0.0118971\n",
      "2017-09-26 12:46:35,959 [MainThread  ] [INFO ]  step 412, loss 0.0201559\n",
      "2017-09-26 12:46:35,977 [MainThread  ] [INFO ]  step 413, loss 0.0167641\n",
      "2017-09-26 12:46:36,078 [MainThread  ] [INFO ]  step 414, loss 0.00497553\n",
      "2017-09-26 12:46:36,098 [MainThread  ] [INFO ]  step 415, loss 0.0211728\n",
      "2017-09-26 12:46:36,111 [MainThread  ] [INFO ]  step 416, loss 0.0174233\n",
      "2017-09-26 12:46:36,125 [MainThread  ] [INFO ]  step 417, loss 0.010853\n",
      "2017-09-26 12:46:36,141 [MainThread  ] [INFO ]  step 418, loss 0.00848207\n",
      "2017-09-26 12:46:36,159 [MainThread  ] [INFO ]  step 419, loss 0.00629045\n",
      "2017-09-26 12:46:36,180 [MainThread  ] [INFO ]  step 420, loss 0.0121085\n",
      "2017-09-26 12:46:36,195 [MainThread  ] [INFO ]  step 421, loss 0.00457905\n",
      "2017-09-26 12:46:36,215 [MainThread  ] [INFO ]  step 422, loss 0.0138817\n"
     ]
    }
   ],
   "source": [
    "reload(train)\n",
    "\n",
    "logging.info('start training ...')\n",
    "start_time = time.time()\n",
    "\n",
    "finished = False\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    session_conf = tf.ConfigProto(\n",
    "        allow_soft_placement=True, log_device_placement=False)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        X = tf.placeholder('float32', (None, embedding_size), name='X')\n",
    "\n",
    "        model = train.FCNN(batch_size=batch_size, sizes=sizes, \n",
    "                        learning_rate=learning_rate,\n",
    "                        batch_norm=False)\n",
    "        train_op = model.optimize(X)\n",
    "\n",
    "        init_local = tf.local_variables_initializer()\n",
    "        init_global = tf.global_variables_initializer()\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        model.init_summary('train')\n",
    "#         model.init_summary('val')\n",
    "\n",
    "        tr_batch = data_flow.gen_batches(docs, triples_train[:1000*batch_size], batch_size)\n",
    "#         val_batch = data_flow.gen_batches(docs, triples_val, 64)\n",
    "\n",
    "        for step, X_train in enumerate(tr_batch):\n",
    "            assert not X_train.isnull().values.any()\n",
    "            _, loss, summary, _embeds = sess.run([\n",
    "                train_op, model.loss_op,\n",
    "                model.merged_summary_op, model.negative\n",
    "            ], feed_dict = {model.phase: 1, 'X:0': X_train})\n",
    "            model.add_summary(summary, step)\n",
    "            logging.info('step %s, loss %s' % (step, loss))\n",
    "            \n",
    "#             if (step + 1) %  50 == 0:\n",
    "#                 X_val = next(val_batch)\n",
    "#                 [val_loss] = sess.run([loss], \n",
    "#                               feed_dict={'X:0': X_val,\n",
    "#                                          'phase:0': 0})\n",
    "#             if (step + 1) %  50 == 0:\n",
    "#                 [test_loss, t20, t200] = sess.run([loss, top20, top200], \n",
    "#                              feed_dict={'X:0': X_test,\n",
    "#                                         'phase:0': 0})\n",
    "        model.save(step)\n",
    "        finished = True\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(\"train error\")\n",
    "#     send_email('notebook_url', subject='train error', body=e)\n",
    "finally:\n",
    "    if finished:\n",
    "#     send_email('notebook_url', subject='finished training')\n",
    "        pass\n",
    "        \n",
    "logging.info(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:33:19.215822Z",
     "start_time": "2017-09-26T09:33:19.212103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:31:28.900481Z",
     "start_time": "2017-09-26T09:31:28.894949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T09:35:19.400478Z",
     "start_time": "2017-09-26T09:35:19.394761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'5984b6a4b6b113169a638519'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(X_train.isnull().sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:35:38.553028Z",
     "start_time": "2017-09-26T08:35:34.580028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/2017-09-26 09:59:37.272917-999.meta\r\n"
     ]
    }
   ],
   "source": [
    "model_dir = join(DATA_FOLDER, 'models')\n",
    "!ls {model_dir+'/*.meta'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T07:02:48.580838Z",
     "start_time": "2017-09-26T07:02:48.572992Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_model(model_dir):\n",
    "    fnames = glob(join(model_dir, '*.meta'))\n",
    "    return max(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T07:02:49.078649Z",
     "start_time": "2017-09-26T07:02:49.073200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_embeds, fnames = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T08:20:17.711749Z",
     "start_time": "2017-09-26T08:20:17.634995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5984cfdcb6b11339ac638507</th>\n",
       "      <td>-0.070904</td>\n",
       "      <td>-0.079025</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.124674</td>\n",
       "      <td>0.042777</td>\n",
       "      <td>-0.115827</td>\n",
       "      <td>-0.093083</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>0.211427</td>\n",
       "      <td>-0.157393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124957</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>-0.048094</td>\n",
       "      <td>0.118328</td>\n",
       "      <td>-0.133080</td>\n",
       "      <td>0.178457</td>\n",
       "      <td>0.068682</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>-0.072113</td>\n",
       "      <td>-0.006197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b60eb6b1130a67638525</th>\n",
       "      <td>-0.093332</td>\n",
       "      <td>-0.134331</td>\n",
       "      <td>0.042862</td>\n",
       "      <td>0.091322</td>\n",
       "      <td>0.039671</td>\n",
       "      <td>-0.170402</td>\n",
       "      <td>-0.087734</td>\n",
       "      <td>-0.076436</td>\n",
       "      <td>0.171415</td>\n",
       "      <td>-0.184669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095422</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>-0.061237</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>-0.122674</td>\n",
       "      <td>0.217525</td>\n",
       "      <td>0.042071</td>\n",
       "      <td>0.102225</td>\n",
       "      <td>-0.085225</td>\n",
       "      <td>0.063532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c767b6b113669c638514</th>\n",
       "      <td>-0.135280</td>\n",
       "      <td>-0.273250</td>\n",
       "      <td>0.094752</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>-0.101050</td>\n",
       "      <td>-0.082634</td>\n",
       "      <td>-0.085032</td>\n",
       "      <td>0.042411</td>\n",
       "      <td>0.186556</td>\n",
       "      <td>-0.075589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.070030</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>0.109597</td>\n",
       "      <td>-0.064214</td>\n",
       "      <td>0.151292</td>\n",
       "      <td>-0.031694</td>\n",
       "      <td>-0.191872</td>\n",
       "      <td>-0.034893</td>\n",
       "      <td>-0.017515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984bcb7b6b11367e863852a</th>\n",
       "      <td>-0.086554</td>\n",
       "      <td>-0.165618</td>\n",
       "      <td>0.034228</td>\n",
       "      <td>-0.010814</td>\n",
       "      <td>-0.012863</td>\n",
       "      <td>-0.099385</td>\n",
       "      <td>-0.199918</td>\n",
       "      <td>-0.141837</td>\n",
       "      <td>0.189886</td>\n",
       "      <td>-0.099551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158592</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>-0.082791</td>\n",
       "      <td>0.046680</td>\n",
       "      <td>-0.018892</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.028640</td>\n",
       "      <td>-0.006407</td>\n",
       "      <td>0.100354</td>\n",
       "      <td>0.107548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b9f3b6b11348b46384f9</th>\n",
       "      <td>-0.050859</td>\n",
       "      <td>-0.167190</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>-0.016376</td>\n",
       "      <td>-0.128197</td>\n",
       "      <td>-0.188375</td>\n",
       "      <td>-0.086630</td>\n",
       "      <td>0.190439</td>\n",
       "      <td>-0.121576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120927</td>\n",
       "      <td>0.058621</td>\n",
       "      <td>-0.090057</td>\n",
       "      <td>0.048432</td>\n",
       "      <td>-0.035487</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.080672</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>0.097629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b84bb6b1132eed63850a</th>\n",
       "      <td>0.077113</td>\n",
       "      <td>-0.139069</td>\n",
       "      <td>0.067594</td>\n",
       "      <td>0.115411</td>\n",
       "      <td>0.022458</td>\n",
       "      <td>-0.181884</td>\n",
       "      <td>-0.113269</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>0.160398</td>\n",
       "      <td>-0.097980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091350</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>-0.110971</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>-0.094551</td>\n",
       "      <td>0.133188</td>\n",
       "      <td>0.069467</td>\n",
       "      <td>0.021368</td>\n",
       "      <td>-0.010850</td>\n",
       "      <td>0.148509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d127b6b11342e563853d</th>\n",
       "      <td>-0.214958</td>\n",
       "      <td>-0.284785</td>\n",
       "      <td>0.073127</td>\n",
       "      <td>0.074833</td>\n",
       "      <td>-0.081186</td>\n",
       "      <td>-0.091073</td>\n",
       "      <td>-0.132739</td>\n",
       "      <td>0.064680</td>\n",
       "      <td>0.277427</td>\n",
       "      <td>-0.082780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040122</td>\n",
       "      <td>-0.037749</td>\n",
       "      <td>-0.048169</td>\n",
       "      <td>0.150314</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>0.198596</td>\n",
       "      <td>-0.130207</td>\n",
       "      <td>-0.175246</td>\n",
       "      <td>-0.045839</td>\n",
       "      <td>-0.044711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c953b6b1137aab638510</th>\n",
       "      <td>-0.161499</td>\n",
       "      <td>-0.288309</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.092653</td>\n",
       "      <td>-0.083072</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>-0.083609</td>\n",
       "      <td>0.040919</td>\n",
       "      <td>0.247058</td>\n",
       "      <td>-0.101859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071387</td>\n",
       "      <td>0.042631</td>\n",
       "      <td>-0.036093</td>\n",
       "      <td>0.136812</td>\n",
       "      <td>-0.009811</td>\n",
       "      <td>0.173574</td>\n",
       "      <td>-0.092945</td>\n",
       "      <td>-0.168592</td>\n",
       "      <td>-0.038722</td>\n",
       "      <td>-0.044352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d891b6b11311c6638512</th>\n",
       "      <td>-0.068388</td>\n",
       "      <td>-0.110483</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>-0.120908</td>\n",
       "      <td>-0.200254</td>\n",
       "      <td>-0.042018</td>\n",
       "      <td>0.182779</td>\n",
       "      <td>-0.116661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109574</td>\n",
       "      <td>-0.008917</td>\n",
       "      <td>-0.142562</td>\n",
       "      <td>0.052248</td>\n",
       "      <td>-0.070965</td>\n",
       "      <td>0.062712</td>\n",
       "      <td>0.106728</td>\n",
       "      <td>-0.016387</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>0.074611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984ca1eb6b113032e638502</th>\n",
       "      <td>0.007926</td>\n",
       "      <td>-0.203619</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.034557</td>\n",
       "      <td>-0.032630</td>\n",
       "      <td>-0.109608</td>\n",
       "      <td>-0.154564</td>\n",
       "      <td>-0.086624</td>\n",
       "      <td>0.222286</td>\n",
       "      <td>-0.027600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106201</td>\n",
       "      <td>0.049224</td>\n",
       "      <td>-0.178163</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>-0.109470</td>\n",
       "      <td>-0.069428</td>\n",
       "      <td>0.119329</td>\n",
       "      <td>-0.040990</td>\n",
       "      <td>-0.088505</td>\n",
       "      <td>-0.013060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b96cb6b1133eff638533</th>\n",
       "      <td>-0.010528</td>\n",
       "      <td>-0.179871</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.053601</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>-0.057862</td>\n",
       "      <td>-0.136716</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0.190263</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048373</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>-0.097421</td>\n",
       "      <td>0.091412</td>\n",
       "      <td>-0.073910</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>-0.032574</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>-0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d9f0b6b113185b638509</th>\n",
       "      <td>-0.019224</td>\n",
       "      <td>-0.149305</td>\n",
       "      <td>0.092725</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>-0.117625</td>\n",
       "      <td>-0.151169</td>\n",
       "      <td>-0.034776</td>\n",
       "      <td>0.205470</td>\n",
       "      <td>-0.093984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>0.050136</td>\n",
       "      <td>-0.160809</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>-0.060546</td>\n",
       "      <td>0.031892</td>\n",
       "      <td>0.126318</td>\n",
       "      <td>-0.046084</td>\n",
       "      <td>-0.015508</td>\n",
       "      <td>0.032114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984dce5b6b1133021638521</th>\n",
       "      <td>0.031013</td>\n",
       "      <td>-0.167272</td>\n",
       "      <td>0.132159</td>\n",
       "      <td>0.107955</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>-0.105131</td>\n",
       "      <td>-0.138948</td>\n",
       "      <td>-0.036137</td>\n",
       "      <td>0.146638</td>\n",
       "      <td>-0.054856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>-0.117396</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>-0.037561</td>\n",
       "      <td>0.009295</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>-0.025677</td>\n",
       "      <td>-0.086919</td>\n",
       "      <td>0.144193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984ba27b6b11349dd638541</th>\n",
       "      <td>0.036730</td>\n",
       "      <td>-0.151344</td>\n",
       "      <td>0.119396</td>\n",
       "      <td>0.075834</td>\n",
       "      <td>0.047956</td>\n",
       "      <td>-0.132797</td>\n",
       "      <td>-0.160387</td>\n",
       "      <td>-0.022166</td>\n",
       "      <td>0.108946</td>\n",
       "      <td>-0.044339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065958</td>\n",
       "      <td>0.062506</td>\n",
       "      <td>-0.127050</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>-0.017835</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>-0.033126</td>\n",
       "      <td>-0.110739</td>\n",
       "      <td>0.107772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b6deb6b11318b563853d</th>\n",
       "      <td>-0.099488</td>\n",
       "      <td>-0.050628</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>0.062351</td>\n",
       "      <td>-0.017439</td>\n",
       "      <td>-0.120838</td>\n",
       "      <td>-0.029962</td>\n",
       "      <td>-0.061354</td>\n",
       "      <td>0.186266</td>\n",
       "      <td>-0.168618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130827</td>\n",
       "      <td>-0.021866</td>\n",
       "      <td>-0.103404</td>\n",
       "      <td>0.078365</td>\n",
       "      <td>-0.076385</td>\n",
       "      <td>0.123957</td>\n",
       "      <td>0.118747</td>\n",
       "      <td>0.042114</td>\n",
       "      <td>-0.114569</td>\n",
       "      <td>0.118816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c094b6b11319c2638531</th>\n",
       "      <td>-0.039410</td>\n",
       "      <td>-0.133408</td>\n",
       "      <td>0.071165</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>-0.051428</td>\n",
       "      <td>-0.116711</td>\n",
       "      <td>-0.158994</td>\n",
       "      <td>-0.029304</td>\n",
       "      <td>0.214113</td>\n",
       "      <td>-0.112456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140909</td>\n",
       "      <td>0.015471</td>\n",
       "      <td>-0.142880</td>\n",
       "      <td>0.023899</td>\n",
       "      <td>-0.093642</td>\n",
       "      <td>-0.016021</td>\n",
       "      <td>0.145132</td>\n",
       "      <td>-0.082184</td>\n",
       "      <td>-0.075381</td>\n",
       "      <td>0.064902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b7ecb6b1132a8d638518</th>\n",
       "      <td>-0.060136</td>\n",
       "      <td>-0.108428</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>-0.037990</td>\n",
       "      <td>-0.134037</td>\n",
       "      <td>-0.159477</td>\n",
       "      <td>-0.070017</td>\n",
       "      <td>0.226345</td>\n",
       "      <td>-0.117031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153321</td>\n",
       "      <td>0.035768</td>\n",
       "      <td>-0.123386</td>\n",
       "      <td>0.055189</td>\n",
       "      <td>-0.067360</td>\n",
       "      <td>-0.001839</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>-0.063518</td>\n",
       "      <td>-0.067167</td>\n",
       "      <td>0.061617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984dc10b6b11324ee63852f</th>\n",
       "      <td>-0.082637</td>\n",
       "      <td>-0.023694</td>\n",
       "      <td>-0.010466</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>-0.029290</td>\n",
       "      <td>-0.054725</td>\n",
       "      <td>-0.148575</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>-0.193362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153988</td>\n",
       "      <td>-0.039915</td>\n",
       "      <td>-0.063405</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>-0.040007</td>\n",
       "      <td>0.138410</td>\n",
       "      <td>0.185371</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>-0.090072</td>\n",
       "      <td>0.017502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c60eb6b1135591638535</th>\n",
       "      <td>0.044771</td>\n",
       "      <td>-0.126504</td>\n",
       "      <td>0.070787</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>-0.134594</td>\n",
       "      <td>-0.137872</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.180852</td>\n",
       "      <td>-0.034918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>-0.117368</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>-0.086344</td>\n",
       "      <td>0.049847</td>\n",
       "      <td>0.068356</td>\n",
       "      <td>-0.023324</td>\n",
       "      <td>-0.067817</td>\n",
       "      <td>0.078302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984be77b6b1137da9638538</th>\n",
       "      <td>0.031733</td>\n",
       "      <td>-0.124070</td>\n",
       "      <td>0.102643</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>-0.176461</td>\n",
       "      <td>-0.148846</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>0.128213</td>\n",
       "      <td>-0.027107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038366</td>\n",
       "      <td>0.057984</td>\n",
       "      <td>-0.164539</td>\n",
       "      <td>0.030740</td>\n",
       "      <td>-0.033882</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.084512</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0.093515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c05bb6b11316f1638520</th>\n",
       "      <td>-0.301396</td>\n",
       "      <td>-0.411067</td>\n",
       "      <td>0.161788</td>\n",
       "      <td>0.125435</td>\n",
       "      <td>-0.062486</td>\n",
       "      <td>-0.161638</td>\n",
       "      <td>-0.213528</td>\n",
       "      <td>0.083870</td>\n",
       "      <td>0.036737</td>\n",
       "      <td>-0.076252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104855</td>\n",
       "      <td>-0.040931</td>\n",
       "      <td>-0.103014</td>\n",
       "      <td>0.195939</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.256267</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.096003</td>\n",
       "      <td>0.109232</td>\n",
       "      <td>-0.092086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d13db6b113441563850c</th>\n",
       "      <td>-0.043556</td>\n",
       "      <td>-0.085950</td>\n",
       "      <td>0.039623</td>\n",
       "      <td>0.093041</td>\n",
       "      <td>-0.004591</td>\n",
       "      <td>-0.115130</td>\n",
       "      <td>-0.125998</td>\n",
       "      <td>-0.007914</td>\n",
       "      <td>0.223921</td>\n",
       "      <td>-0.171760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102217</td>\n",
       "      <td>-0.002180</td>\n",
       "      <td>-0.079908</td>\n",
       "      <td>0.050655</td>\n",
       "      <td>-0.094040</td>\n",
       "      <td>0.154085</td>\n",
       "      <td>0.071195</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>-0.037008</td>\n",
       "      <td>0.045334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984ba26b6b11349e6638538</th>\n",
       "      <td>-0.044764</td>\n",
       "      <td>-0.100461</td>\n",
       "      <td>0.055970</td>\n",
       "      <td>0.117337</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>-0.108109</td>\n",
       "      <td>-0.141613</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.214180</td>\n",
       "      <td>-0.202214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099908</td>\n",
       "      <td>-0.042193</td>\n",
       "      <td>-0.113638</td>\n",
       "      <td>0.048793</td>\n",
       "      <td>-0.117175</td>\n",
       "      <td>0.151505</td>\n",
       "      <td>0.094810</td>\n",
       "      <td>0.046270</td>\n",
       "      <td>-0.050515</td>\n",
       "      <td>0.066495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d7d9b6b11306b763854f</th>\n",
       "      <td>0.019165</td>\n",
       "      <td>-0.073874</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.059177</td>\n",
       "      <td>-0.155544</td>\n",
       "      <td>-0.091977</td>\n",
       "      <td>0.077144</td>\n",
       "      <td>0.187094</td>\n",
       "      <td>-0.112855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144469</td>\n",
       "      <td>-0.012743</td>\n",
       "      <td>-0.051931</td>\n",
       "      <td>-0.006904</td>\n",
       "      <td>-0.188349</td>\n",
       "      <td>0.167607</td>\n",
       "      <td>0.048308</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.019393</td>\n",
       "      <td>0.021397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984cbe7b6b113179b638537</th>\n",
       "      <td>-0.040516</td>\n",
       "      <td>-0.134426</td>\n",
       "      <td>0.068749</td>\n",
       "      <td>0.057119</td>\n",
       "      <td>-0.042904</td>\n",
       "      <td>-0.068592</td>\n",
       "      <td>-0.056612</td>\n",
       "      <td>-0.073193</td>\n",
       "      <td>0.226471</td>\n",
       "      <td>-0.043008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>-0.008012</td>\n",
       "      <td>0.097617</td>\n",
       "      <td>-0.008982</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.052718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c3abb6b1133ee5638513</th>\n",
       "      <td>-0.024172</td>\n",
       "      <td>-0.135875</td>\n",
       "      <td>0.077057</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>-0.043395</td>\n",
       "      <td>-0.068827</td>\n",
       "      <td>-0.050596</td>\n",
       "      <td>-0.086996</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>-0.016224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080167</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>-0.018962</td>\n",
       "      <td>0.090216</td>\n",
       "      <td>-0.006052</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>0.045998</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.035536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b9d6b6b11346c3638510</th>\n",
       "      <td>-0.086411</td>\n",
       "      <td>-0.079300</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>0.166974</td>\n",
       "      <td>0.074387</td>\n",
       "      <td>-0.094428</td>\n",
       "      <td>-0.047318</td>\n",
       "      <td>-0.075852</td>\n",
       "      <td>0.059037</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074485</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>-0.028844</td>\n",
       "      <td>0.185817</td>\n",
       "      <td>-0.133545</td>\n",
       "      <td>0.136431</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>-0.122860</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>0.069086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984cfe7b6b11339ba63854e</th>\n",
       "      <td>-0.047011</td>\n",
       "      <td>-0.129834</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.122479</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>-0.093304</td>\n",
       "      <td>-0.066458</td>\n",
       "      <td>0.044095</td>\n",
       "      <td>0.188615</td>\n",
       "      <td>-0.181589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133825</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>-0.169748</td>\n",
       "      <td>-0.043093</td>\n",
       "      <td>-0.060159</td>\n",
       "      <td>0.156265</td>\n",
       "      <td>0.070572</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.129823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984be78b6b1137daa638541</th>\n",
       "      <td>-0.021329</td>\n",
       "      <td>-0.115979</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.158419</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>-0.129828</td>\n",
       "      <td>-0.089169</td>\n",
       "      <td>0.107662</td>\n",
       "      <td>0.221353</td>\n",
       "      <td>-0.147015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106201</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>-0.149536</td>\n",
       "      <td>0.011263</td>\n",
       "      <td>-0.087812</td>\n",
       "      <td>0.131334</td>\n",
       "      <td>0.065993</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>-0.038683</td>\n",
       "      <td>0.055032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c4cbb6b11348ac638527</th>\n",
       "      <td>0.011411</td>\n",
       "      <td>-0.029645</td>\n",
       "      <td>0.055459</td>\n",
       "      <td>0.035079</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>-0.136542</td>\n",
       "      <td>-0.187036</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.180461</td>\n",
       "      <td>-0.133239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128028</td>\n",
       "      <td>-0.030979</td>\n",
       "      <td>-0.084993</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>-0.077086</td>\n",
       "      <td>0.176131</td>\n",
       "      <td>0.254272</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>-0.013059</td>\n",
       "      <td>0.078096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c96ab6b1137bb763850d</th>\n",
       "      <td>-0.239556</td>\n",
       "      <td>-0.101251</td>\n",
       "      <td>0.144934</td>\n",
       "      <td>0.036174</td>\n",
       "      <td>-0.072830</td>\n",
       "      <td>-0.148084</td>\n",
       "      <td>-0.198515</td>\n",
       "      <td>0.077365</td>\n",
       "      <td>0.176133</td>\n",
       "      <td>-0.126462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071033</td>\n",
       "      <td>0.094468</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.099159</td>\n",
       "      <td>0.046288</td>\n",
       "      <td>0.108412</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>-0.040528</td>\n",
       "      <td>-0.058956</td>\n",
       "      <td>-0.007832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984ba53b6b1134c29638506</th>\n",
       "      <td>-0.126162</td>\n",
       "      <td>-0.257472</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>-0.029228</td>\n",
       "      <td>-0.075176</td>\n",
       "      <td>-0.173388</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.165687</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102118</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.054182</td>\n",
       "      <td>-0.027284</td>\n",
       "      <td>0.083180</td>\n",
       "      <td>-0.030648</td>\n",
       "      <td>-0.101566</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>0.066609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984bebbb6b1130134638551</th>\n",
       "      <td>0.011607</td>\n",
       "      <td>-0.097534</td>\n",
       "      <td>0.063467</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>-0.118940</td>\n",
       "      <td>-0.170798</td>\n",
       "      <td>-0.023520</td>\n",
       "      <td>0.189717</td>\n",
       "      <td>-0.130241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134079</td>\n",
       "      <td>-0.013272</td>\n",
       "      <td>-0.152889</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>-0.070984</td>\n",
       "      <td>0.083751</td>\n",
       "      <td>0.072275</td>\n",
       "      <td>-0.050179</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.124650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d303b6b1135bce6384f2</th>\n",
       "      <td>-0.156548</td>\n",
       "      <td>-0.305342</td>\n",
       "      <td>0.091420</td>\n",
       "      <td>0.099335</td>\n",
       "      <td>-0.086955</td>\n",
       "      <td>-0.172023</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.062296</td>\n",
       "      <td>0.231394</td>\n",
       "      <td>-0.125067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062612</td>\n",
       "      <td>0.069984</td>\n",
       "      <td>-0.033074</td>\n",
       "      <td>0.069949</td>\n",
       "      <td>-0.095368</td>\n",
       "      <td>0.189822</td>\n",
       "      <td>-0.084794</td>\n",
       "      <td>-0.144569</td>\n",
       "      <td>-0.062745</td>\n",
       "      <td>-0.040621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c96fb6b1137bcc638535</th>\n",
       "      <td>-0.099408</td>\n",
       "      <td>-0.302550</td>\n",
       "      <td>0.101611</td>\n",
       "      <td>0.118443</td>\n",
       "      <td>-0.100425</td>\n",
       "      <td>-0.120541</td>\n",
       "      <td>-0.006548</td>\n",
       "      <td>0.047315</td>\n",
       "      <td>0.219971</td>\n",
       "      <td>-0.137309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058276</td>\n",
       "      <td>0.067752</td>\n",
       "      <td>-0.012801</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>-0.121783</td>\n",
       "      <td>0.185478</td>\n",
       "      <td>-0.068655</td>\n",
       "      <td>-0.164741</td>\n",
       "      <td>-0.069925</td>\n",
       "      <td>-0.041272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984c6c6b6b1135e88638507</th>\n",
       "      <td>0.037674</td>\n",
       "      <td>-0.193093</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>0.066942</td>\n",
       "      <td>-0.004347</td>\n",
       "      <td>-0.117634</td>\n",
       "      <td>-0.119414</td>\n",
       "      <td>-0.014574</td>\n",
       "      <td>0.201626</td>\n",
       "      <td>-0.180846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068612</td>\n",
       "      <td>0.056040</td>\n",
       "      <td>-0.127614</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>-0.064787</td>\n",
       "      <td>0.178343</td>\n",
       "      <td>0.088145</td>\n",
       "      <td>-0.025295</td>\n",
       "      <td>-0.030033</td>\n",
       "      <td>0.125115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984cb73b6b113132863851b</th>\n",
       "      <td>-0.019321</td>\n",
       "      <td>-0.124828</td>\n",
       "      <td>0.049712</td>\n",
       "      <td>0.058186</td>\n",
       "      <td>-0.028364</td>\n",
       "      <td>-0.159842</td>\n",
       "      <td>-0.113259</td>\n",
       "      <td>0.067176</td>\n",
       "      <td>0.219580</td>\n",
       "      <td>-0.122160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093188</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>-0.122607</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>-0.099124</td>\n",
       "      <td>0.084971</td>\n",
       "      <td>0.068650</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>-0.055202</td>\n",
       "      <td>0.044186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b926b6b1133ca0638504</th>\n",
       "      <td>-0.018743</td>\n",
       "      <td>-0.139234</td>\n",
       "      <td>0.065593</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>-0.012923</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.145341</td>\n",
       "      <td>0.050226</td>\n",
       "      <td>0.219226</td>\n",
       "      <td>-0.077674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069895</td>\n",
       "      <td>0.051203</td>\n",
       "      <td>-0.117993</td>\n",
       "      <td>0.049619</td>\n",
       "      <td>-0.105532</td>\n",
       "      <td>0.075415</td>\n",
       "      <td>0.092338</td>\n",
       "      <td>-0.009637</td>\n",
       "      <td>-0.046667</td>\n",
       "      <td>0.052187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984ced6b6b1132ce6638534</th>\n",
       "      <td>-0.054234</td>\n",
       "      <td>-0.128143</td>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.072117</td>\n",
       "      <td>-0.065126</td>\n",
       "      <td>-0.110086</td>\n",
       "      <td>-0.110514</td>\n",
       "      <td>-0.021451</td>\n",
       "      <td>0.187089</td>\n",
       "      <td>-0.097422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065898</td>\n",
       "      <td>0.040442</td>\n",
       "      <td>-0.158972</td>\n",
       "      <td>0.082102</td>\n",
       "      <td>-0.073780</td>\n",
       "      <td>0.073246</td>\n",
       "      <td>0.070662</td>\n",
       "      <td>0.039913</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.061612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984bc55b6b113645d63852a</th>\n",
       "      <td>-0.123046</td>\n",
       "      <td>-0.047869</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>-0.037443</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>-0.148726</td>\n",
       "      <td>-0.152462</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>0.154666</td>\n",
       "      <td>-0.173704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161533</td>\n",
       "      <td>0.085766</td>\n",
       "      <td>-0.187030</td>\n",
       "      <td>0.133476</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.162324</td>\n",
       "      <td>-0.041240</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>0.064091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984b689b6b113148b638545</th>\n",
       "      <td>-0.095991</td>\n",
       "      <td>-0.093912</td>\n",
       "      <td>0.032138</td>\n",
       "      <td>-0.048770</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>-0.203640</td>\n",
       "      <td>-0.191206</td>\n",
       "      <td>-0.193492</td>\n",
       "      <td>0.167119</td>\n",
       "      <td>-0.189671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222799</td>\n",
       "      <td>0.133185</td>\n",
       "      <td>-0.186100</td>\n",
       "      <td>0.097482</td>\n",
       "      <td>0.112392</td>\n",
       "      <td>0.080984</td>\n",
       "      <td>0.162461</td>\n",
       "      <td>-0.031033</td>\n",
       "      <td>0.011217</td>\n",
       "      <td>0.045428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984d036b6b1133d1f6384f9</th>\n",
       "      <td>-0.031770</td>\n",
       "      <td>-0.055385</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>-0.022870</td>\n",
       "      <td>-0.192538</td>\n",
       "      <td>-0.014517</td>\n",
       "      <td>-0.137099</td>\n",
       "      <td>-0.150673</td>\n",
       "      <td>0.245795</td>\n",
       "      <td>-0.221669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>-0.012872</td>\n",
       "      <td>-0.097214</td>\n",
       "      <td>0.039653</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>0.163789</td>\n",
       "      <td>0.202660</td>\n",
       "      <td>-0.043390</td>\n",
       "      <td>-0.025453</td>\n",
       "      <td>0.071054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1         2         3         4    \\\n",
       "5984cfdcb6b11339ac638507 -0.070904 -0.079025  0.037895  0.124674  0.042777   \n",
       "5984b60eb6b1130a67638525 -0.093332 -0.134331  0.042862  0.091322  0.039671   \n",
       "5984c767b6b113669c638514 -0.135280 -0.273250  0.094752  0.083100 -0.101050   \n",
       "5984bcb7b6b11367e863852a -0.086554 -0.165618  0.034228 -0.010814 -0.012863   \n",
       "5984b9f3b6b11348b46384f9 -0.050859 -0.167190  0.022801  0.024430 -0.016376   \n",
       "5984b84bb6b1132eed63850a  0.077113 -0.139069  0.067594  0.115411  0.022458   \n",
       "5984d127b6b11342e563853d -0.214958 -0.284785  0.073127  0.074833 -0.081186   \n",
       "5984c953b6b1137aab638510 -0.161499 -0.288309  0.092800  0.092653 -0.083072   \n",
       "5984d891b6b11311c6638512 -0.068388 -0.110483  0.038842  0.043768  0.007147   \n",
       "5984ca1eb6b113032e638502  0.007926 -0.203619  0.054011  0.034557 -0.032630   \n",
       "5984b96cb6b1133eff638533 -0.010528 -0.179871  0.025764  0.053601  0.051163   \n",
       "5984d9f0b6b113185b638509 -0.019224 -0.149305  0.092725  0.046188  0.003301   \n",
       "5984dce5b6b1133021638521  0.031013 -0.167272  0.132159  0.107955  0.052381   \n",
       "5984ba27b6b11349dd638541  0.036730 -0.151344  0.119396  0.075834  0.047956   \n",
       "5984b6deb6b11318b563853d -0.099488 -0.050628  0.031227  0.062351 -0.017439   \n",
       "5984c094b6b11319c2638531 -0.039410 -0.133408  0.071165  0.013798 -0.051428   \n",
       "5984b7ecb6b1132a8d638518 -0.060136 -0.108428  0.063500  0.002232 -0.037990   \n",
       "5984dc10b6b11324ee63852f -0.082637 -0.023694 -0.010466  0.010496 -0.029290   \n",
       "5984c60eb6b1135591638535  0.044771 -0.126504  0.070787  0.060699  0.030708   \n",
       "5984be77b6b1137da9638538  0.031733 -0.124070  0.102643  0.077700  0.013326   \n",
       "5984c05bb6b11316f1638520 -0.301396 -0.411067  0.161788  0.125435 -0.062486   \n",
       "5984d13db6b113441563850c -0.043556 -0.085950  0.039623  0.093041 -0.004591   \n",
       "5984ba26b6b11349e6638538 -0.044764 -0.100461  0.055970  0.117337  0.010927   \n",
       "5984d7d9b6b11306b763854f  0.019165 -0.073874  0.025002  0.117152  0.059177   \n",
       "5984cbe7b6b113179b638537 -0.040516 -0.134426  0.068749  0.057119 -0.042904   \n",
       "5984c3abb6b1133ee5638513 -0.024172 -0.135875  0.077057  0.078067 -0.043395   \n",
       "5984b9d6b6b11346c3638510 -0.086411 -0.079300 -0.038326  0.166974  0.074387   \n",
       "5984cfe7b6b11339ba63854e -0.047011 -0.129834  0.009750  0.122479  0.004265   \n",
       "5984be78b6b1137daa638541 -0.021329 -0.115979  0.017793  0.158419  0.015102   \n",
       "5984c4cbb6b11348ac638527  0.011411 -0.029645  0.055459  0.035079  0.038940   \n",
       "5984c96ab6b1137bb763850d -0.239556 -0.101251  0.144934  0.036174 -0.072830   \n",
       "5984ba53b6b1134c29638506 -0.126162 -0.257472  0.038246  0.041431 -0.029228   \n",
       "5984bebbb6b1130134638551  0.011607 -0.097534  0.063467  0.060259  0.017659   \n",
       "5984d303b6b1135bce6384f2 -0.156548 -0.305342  0.091420  0.099335 -0.086955   \n",
       "5984c96fb6b1137bcc638535 -0.099408 -0.302550  0.101611  0.118443 -0.100425   \n",
       "5984c6c6b6b1135e88638507  0.037674 -0.193093  0.082215  0.066942 -0.004347   \n",
       "5984cb73b6b113132863851b -0.019321 -0.124828  0.049712  0.058186 -0.028364   \n",
       "5984b926b6b1133ca0638504 -0.018743 -0.139234  0.065593  0.052000 -0.012923   \n",
       "5984ced6b6b1132ce6638534 -0.054234 -0.128143  0.062468  0.072117 -0.065126   \n",
       "5984bc55b6b113645d63852a -0.123046 -0.047869  0.013360 -0.037443  0.001947   \n",
       "5984b689b6b113148b638545 -0.095991 -0.093912  0.032138 -0.048770  0.005202   \n",
       "5984d036b6b1133d1f6384f9 -0.031770 -0.055385  0.010320 -0.022870 -0.192538   \n",
       "\n",
       "                               5         6         7         8         9    \\\n",
       "5984cfdcb6b11339ac638507 -0.115827 -0.093083 -0.011540  0.211427 -0.157393   \n",
       "5984b60eb6b1130a67638525 -0.170402 -0.087734 -0.076436  0.171415 -0.184669   \n",
       "5984c767b6b113669c638514 -0.082634 -0.085032  0.042411  0.186556 -0.075589   \n",
       "5984bcb7b6b11367e863852a -0.099385 -0.199918 -0.141837  0.189886 -0.099551   \n",
       "5984b9f3b6b11348b46384f9 -0.128197 -0.188375 -0.086630  0.190439 -0.121576   \n",
       "5984b84bb6b1132eed63850a -0.181884 -0.113269  0.043151  0.160398 -0.097980   \n",
       "5984d127b6b11342e563853d -0.091073 -0.132739  0.064680  0.277427 -0.082780   \n",
       "5984c953b6b1137aab638510 -0.090371 -0.083609  0.040919  0.247058 -0.101859   \n",
       "5984d891b6b11311c6638512 -0.120908 -0.200254 -0.042018  0.182779 -0.116661   \n",
       "5984ca1eb6b113032e638502 -0.109608 -0.154564 -0.086624  0.222286 -0.027600   \n",
       "5984b96cb6b1133eff638533 -0.057862 -0.136716 -0.090000  0.190263  0.019078   \n",
       "5984d9f0b6b113185b638509 -0.117625 -0.151169 -0.034776  0.205470 -0.093984   \n",
       "5984dce5b6b1133021638521 -0.105131 -0.138948 -0.036137  0.146638 -0.054856   \n",
       "5984ba27b6b11349dd638541 -0.132797 -0.160387 -0.022166  0.108946 -0.044339   \n",
       "5984b6deb6b11318b563853d -0.120838 -0.029962 -0.061354  0.186266 -0.168618   \n",
       "5984c094b6b11319c2638531 -0.116711 -0.158994 -0.029304  0.214113 -0.112456   \n",
       "5984b7ecb6b1132a8d638518 -0.134037 -0.159477 -0.070017  0.226345 -0.117031   \n",
       "5984dc10b6b11324ee63852f -0.054725 -0.148575  0.015099  0.211604 -0.193362   \n",
       "5984c60eb6b1135591638535 -0.134594 -0.137872  0.033830  0.180852 -0.034918   \n",
       "5984be77b6b1137da9638538 -0.176461 -0.148846 -0.028591  0.128213 -0.027107   \n",
       "5984c05bb6b11316f1638520 -0.161638 -0.213528  0.083870  0.036737 -0.076252   \n",
       "5984d13db6b113441563850c -0.115130 -0.125998 -0.007914  0.223921 -0.171760   \n",
       "5984ba26b6b11349e6638538 -0.108109 -0.141613  0.001534  0.214180 -0.202214   \n",
       "5984d7d9b6b11306b763854f -0.155544 -0.091977  0.077144  0.187094 -0.112855   \n",
       "5984cbe7b6b113179b638537 -0.068592 -0.056612 -0.073193  0.226471 -0.043008   \n",
       "5984c3abb6b1133ee5638513 -0.068827 -0.050596 -0.086996  0.232356 -0.016224   \n",
       "5984b9d6b6b11346c3638510 -0.094428 -0.047318 -0.075852  0.059037  0.005552   \n",
       "5984cfe7b6b11339ba63854e -0.093304 -0.066458  0.044095  0.188615 -0.181589   \n",
       "5984be78b6b1137daa638541 -0.129828 -0.089169  0.107662  0.221353 -0.147015   \n",
       "5984c4cbb6b11348ac638527 -0.136542 -0.187036  0.121339  0.180461 -0.133239   \n",
       "5984c96ab6b1137bb763850d -0.148084 -0.198515  0.077365  0.176133 -0.126462   \n",
       "5984ba53b6b1134c29638506 -0.075176 -0.173388  0.010356  0.165687  0.006268   \n",
       "5984bebbb6b1130134638551 -0.118940 -0.170798 -0.023520  0.189717 -0.130241   \n",
       "5984d303b6b1135bce6384f2 -0.172023  0.001728  0.062296  0.231394 -0.125067   \n",
       "5984c96fb6b1137bcc638535 -0.120541 -0.006548  0.047315  0.219971 -0.137309   \n",
       "5984c6c6b6b1135e88638507 -0.117634 -0.119414 -0.014574  0.201626 -0.180846   \n",
       "5984cb73b6b113132863851b -0.159842 -0.113259  0.067176  0.219580 -0.122160   \n",
       "5984b926b6b1133ca0638504 -0.153449 -0.145341  0.050226  0.219226 -0.077674   \n",
       "5984ced6b6b1132ce6638534 -0.110086 -0.110514 -0.021451  0.187089 -0.097422   \n",
       "5984bc55b6b113645d63852a -0.148726 -0.152462 -0.157941  0.154666 -0.173704   \n",
       "5984b689b6b113148b638545 -0.203640 -0.191206 -0.193492  0.167119 -0.189671   \n",
       "5984d036b6b1133d1f6384f9 -0.014517 -0.137099 -0.150673  0.245795 -0.221669   \n",
       "\n",
       "                            ...          290       291       292       293  \\\n",
       "5984cfdcb6b11339ac638507    ...     0.124957 -0.044020 -0.048094  0.118328   \n",
       "5984b60eb6b1130a67638525    ...     0.095422 -0.037501 -0.061237  0.083233   \n",
       "5984c767b6b113669c638514    ...     0.002963  0.070030 -0.005793  0.109597   \n",
       "5984bcb7b6b11367e863852a    ...     0.158592  0.053811 -0.082791  0.046680   \n",
       "5984b9f3b6b11348b46384f9    ...     0.120927  0.058621 -0.090057  0.048432   \n",
       "5984b84bb6b1132eed63850a    ...     0.091350 -0.008239 -0.110971  0.042128   \n",
       "5984d127b6b11342e563853d    ...     0.040122 -0.037749 -0.048169  0.150314   \n",
       "5984c953b6b1137aab638510    ...     0.071387  0.042631 -0.036093  0.136812   \n",
       "5984d891b6b11311c6638512    ...     0.109574 -0.008917 -0.142562  0.052248   \n",
       "5984ca1eb6b113032e638502    ...     0.106201  0.049224 -0.178163  0.031375   \n",
       "5984b96cb6b1133eff638533    ...     0.048373  0.001873 -0.097421  0.091412   \n",
       "5984d9f0b6b113185b638509    ...     0.146362  0.050136 -0.160809  0.067627   \n",
       "5984dce5b6b1133021638521    ...     0.064803  0.023060 -0.117396  0.020028   \n",
       "5984ba27b6b11349dd638541    ...     0.065958  0.062506 -0.127050  0.016054   \n",
       "5984b6deb6b11318b563853d    ...     0.130827 -0.021866 -0.103404  0.078365   \n",
       "5984c094b6b11319c2638531    ...     0.140909  0.015471 -0.142880  0.023899   \n",
       "5984b7ecb6b1132a8d638518    ...     0.153321  0.035768 -0.123386  0.055189   \n",
       "5984dc10b6b11324ee63852f    ...     0.153988 -0.039915 -0.063405  0.013037   \n",
       "5984c60eb6b1135591638535    ...     0.028296  0.054175 -0.117368  0.036176   \n",
       "5984be77b6b1137da9638538    ...     0.038366  0.057984 -0.164539  0.030740   \n",
       "5984c05bb6b11316f1638520    ...     0.104855 -0.040931 -0.103014  0.195939   \n",
       "5984d13db6b113441563850c    ...     0.102217 -0.002180 -0.079908  0.050655   \n",
       "5984ba26b6b11349e6638538    ...     0.099908 -0.042193 -0.113638  0.048793   \n",
       "5984d7d9b6b11306b763854f    ...     0.144469 -0.012743 -0.051931 -0.006904   \n",
       "5984cbe7b6b113179b638537    ...     0.084460  0.043362 -0.008012  0.097617   \n",
       "5984c3abb6b1133ee5638513    ...     0.080167  0.034280 -0.018962  0.090216   \n",
       "5984b9d6b6b11346c3638510    ...     0.074485  0.018589 -0.028844  0.185817   \n",
       "5984cfe7b6b11339ba63854e    ...     0.133825 -0.000986 -0.169748 -0.043093   \n",
       "5984be78b6b1137daa638541    ...     0.106201  0.005602 -0.149536  0.011263   \n",
       "5984c4cbb6b11348ac638527    ...     0.128028 -0.030979 -0.084993  0.024202   \n",
       "5984c96ab6b1137bb763850d    ...     0.071033  0.094468  0.001045  0.099159   \n",
       "5984ba53b6b1134c29638506    ...     0.102118  0.008344  0.008923  0.054182   \n",
       "5984bebbb6b1130134638551    ...     0.134079 -0.013272 -0.152889  0.001292   \n",
       "5984d303b6b1135bce6384f2    ...     0.062612  0.069984 -0.033074  0.069949   \n",
       "5984c96fb6b1137bcc638535    ...     0.058276  0.067752 -0.012801  0.106858   \n",
       "5984c6c6b6b1135e88638507    ...     0.068612  0.056040 -0.127614  0.014894   \n",
       "5984cb73b6b113132863851b    ...     0.093188  0.045101 -0.122607  0.049789   \n",
       "5984b926b6b1133ca0638504    ...     0.069895  0.051203 -0.117993  0.049619   \n",
       "5984ced6b6b1132ce6638534    ...     0.065898  0.040442 -0.158972  0.082102   \n",
       "5984bc55b6b113645d63852a    ...     0.161533  0.085766 -0.187030  0.133476   \n",
       "5984b689b6b113148b638545    ...     0.222799  0.133185 -0.186100  0.097482   \n",
       "5984d036b6b1133d1f6384f9    ...     0.112049 -0.012872 -0.097214  0.039653   \n",
       "\n",
       "                               294       295       296       297       298  \\\n",
       "5984cfdcb6b11339ac638507 -0.133080  0.178457  0.068682  0.060002 -0.072113   \n",
       "5984b60eb6b1130a67638525 -0.122674  0.217525  0.042071  0.102225 -0.085225   \n",
       "5984c767b6b113669c638514 -0.064214  0.151292 -0.031694 -0.191872 -0.034893   \n",
       "5984bcb7b6b11367e863852a -0.018892  0.008599  0.028640 -0.006407  0.100354   \n",
       "5984b9f3b6b11348b46384f9 -0.035487  0.056100  0.080672  0.014886  0.097365   \n",
       "5984b84bb6b1132eed63850a -0.094551  0.133188  0.069467  0.021368 -0.010850   \n",
       "5984d127b6b11342e563853d -0.006512  0.198596 -0.130207 -0.175246 -0.045839   \n",
       "5984c953b6b1137aab638510 -0.009811  0.173574 -0.092945 -0.168592 -0.038722   \n",
       "5984d891b6b11311c6638512 -0.070965  0.062712  0.106728 -0.016387  0.060623   \n",
       "5984ca1eb6b113032e638502 -0.109470 -0.069428  0.119329 -0.040990 -0.088505   \n",
       "5984b96cb6b1133eff638533 -0.073910  0.043181  0.007917 -0.032574  0.002056   \n",
       "5984d9f0b6b113185b638509 -0.060546  0.031892  0.126318 -0.046084 -0.015508   \n",
       "5984dce5b6b1133021638521 -0.037561  0.009295  0.034234 -0.025677 -0.086919   \n",
       "5984ba27b6b11349dd638541 -0.017835  0.010164  0.022540 -0.033126 -0.110739   \n",
       "5984b6deb6b11318b563853d -0.076385  0.123957  0.118747  0.042114 -0.114569   \n",
       "5984c094b6b11319c2638531 -0.093642 -0.016021  0.145132 -0.082184 -0.075381   \n",
       "5984b7ecb6b1132a8d638518 -0.067360 -0.001839  0.109311 -0.063518 -0.067167   \n",
       "5984dc10b6b11324ee63852f -0.040007  0.138410  0.185371  0.007432 -0.090072   \n",
       "5984c60eb6b1135591638535 -0.086344  0.049847  0.068356 -0.023324 -0.067817   \n",
       "5984be77b6b1137da9638538 -0.033882  0.029041  0.084512  0.014698 -0.120222   \n",
       "5984c05bb6b11316f1638520 -0.000262  0.256267 -0.091886 -0.096003  0.109232   \n",
       "5984d13db6b113441563850c -0.094040  0.154085  0.071195  0.037495 -0.037008   \n",
       "5984ba26b6b11349e6638538 -0.117175  0.151505  0.094810  0.046270 -0.050515   \n",
       "5984d7d9b6b11306b763854f -0.188349  0.167607  0.048308  0.019470  0.019393   \n",
       "5984cbe7b6b113179b638537 -0.008982  0.052366  0.011577  0.062537  0.019638   \n",
       "5984c3abb6b1133ee5638513 -0.006052  0.021938  0.024757  0.045998  0.023933   \n",
       "5984b9d6b6b11346c3638510 -0.133545  0.136431  0.127706 -0.122860 -0.043091   \n",
       "5984cfe7b6b11339ba63854e -0.060159  0.156265  0.070572  0.032421  0.008774   \n",
       "5984be78b6b1137daa638541 -0.087812  0.131334  0.065993  0.028678 -0.038683   \n",
       "5984c4cbb6b11348ac638527 -0.077086  0.176131  0.254272  0.011592 -0.013059   \n",
       "5984c96ab6b1137bb763850d  0.046288  0.108412  0.022529 -0.040528 -0.058956   \n",
       "5984ba53b6b1134c29638506 -0.027284  0.083180 -0.030648 -0.101566  0.018225   \n",
       "5984bebbb6b1130134638551 -0.070984  0.083751  0.072275 -0.050179  0.007784   \n",
       "5984d303b6b1135bce6384f2 -0.095368  0.189822 -0.084794 -0.144569 -0.062745   \n",
       "5984c96fb6b1137bcc638535 -0.121783  0.185478 -0.068655 -0.164741 -0.069925   \n",
       "5984c6c6b6b1135e88638507 -0.064787  0.178343  0.088145 -0.025295 -0.030033   \n",
       "5984cb73b6b113132863851b -0.099124  0.084971  0.068650  0.003065 -0.055202   \n",
       "5984b926b6b1133ca0638504 -0.105532  0.075415  0.092338 -0.009637 -0.046667   \n",
       "5984ced6b6b1132ce6638534 -0.073780  0.073246  0.070662  0.039913  0.037054   \n",
       "5984bc55b6b113645d63852a  0.045197  0.027177  0.162324 -0.041240 -0.015195   \n",
       "5984b689b6b113148b638545  0.112392  0.080984  0.162461 -0.031033  0.011217   \n",
       "5984d036b6b1133d1f6384f9  0.066962  0.163789  0.202660 -0.043390 -0.025453   \n",
       "\n",
       "                               299  \n",
       "5984cfdcb6b11339ac638507 -0.006197  \n",
       "5984b60eb6b1130a67638525  0.063532  \n",
       "5984c767b6b113669c638514 -0.017515  \n",
       "5984bcb7b6b11367e863852a  0.107548  \n",
       "5984b9f3b6b11348b46384f9  0.097629  \n",
       "5984b84bb6b1132eed63850a  0.148509  \n",
       "5984d127b6b11342e563853d -0.044711  \n",
       "5984c953b6b1137aab638510 -0.044352  \n",
       "5984d891b6b11311c6638512  0.074611  \n",
       "5984ca1eb6b113032e638502 -0.013060  \n",
       "5984b96cb6b1133eff638533 -0.008618  \n",
       "5984d9f0b6b113185b638509  0.032114  \n",
       "5984dce5b6b1133021638521  0.144193  \n",
       "5984ba27b6b11349dd638541  0.107772  \n",
       "5984b6deb6b11318b563853d  0.118816  \n",
       "5984c094b6b11319c2638531  0.064902  \n",
       "5984b7ecb6b1132a8d638518  0.061617  \n",
       "5984dc10b6b11324ee63852f  0.017502  \n",
       "5984c60eb6b1135591638535  0.078302  \n",
       "5984be77b6b1137da9638538  0.093515  \n",
       "5984c05bb6b11316f1638520 -0.092086  \n",
       "5984d13db6b113441563850c  0.045334  \n",
       "5984ba26b6b11349e6638538  0.066495  \n",
       "5984d7d9b6b11306b763854f  0.021397  \n",
       "5984cbe7b6b113179b638537  0.052718  \n",
       "5984c3abb6b1133ee5638513  0.035536  \n",
       "5984b9d6b6b11346c3638510  0.069086  \n",
       "5984cfe7b6b11339ba63854e  0.129823  \n",
       "5984be78b6b1137daa638541  0.055032  \n",
       "5984c4cbb6b11348ac638527  0.078096  \n",
       "5984c96ab6b1137bb763850d -0.007832  \n",
       "5984ba53b6b1134c29638506  0.066609  \n",
       "5984bebbb6b1130134638551  0.124650  \n",
       "5984d303b6b1135bce6384f2 -0.040621  \n",
       "5984c96fb6b1137bcc638535 -0.041272  \n",
       "5984c6c6b6b1135e88638507  0.125115  \n",
       "5984cb73b6b113132863851b  0.044186  \n",
       "5984b926b6b1133ca0638504  0.052187  \n",
       "5984ced6b6b1132ce6638534  0.061612  \n",
       "5984bc55b6b113645d63852a  0.064091  \n",
       "5984b689b6b113148b638545  0.045428  \n",
       "5984d036b6b1133d1f6384f9  0.071054  \n",
       "\n",
       "[42 rows x 300 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T07:02:51.935759Z",
     "start_time": "2017-09-26T07:02:50.079435Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../data/models/2017-09-26 09:59:37.272917-999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-26 10:02:50,512 [MainThread  ] [INFO ]  Restoring parameters from ../data/models/2017-09-26 09:59:37.272917-999\n",
      "2017-09-26 10:02:50,687 [MainThread  ] [INFO ]  step 0, loss 0.0\n",
      "2017-09-26 10:02:50,693 [MainThread  ] [INFO ]  step 1, loss 0.0\n",
      "2017-09-26 10:02:50,698 [MainThread  ] [INFO ]  step 2, loss 0.0\n",
      "2017-09-26 10:02:50,708 [MainThread  ] [INFO ]  step 3, loss 0.0\n",
      "2017-09-26 10:02:50,715 [MainThread  ] [INFO ]  step 4, loss 0.0\n",
      "2017-09-26 10:02:50,720 [MainThread  ] [INFO ]  step 5, loss 0.0\n",
      "2017-09-26 10:02:50,728 [MainThread  ] [INFO ]  step 6, loss 0.0\n",
      "2017-09-26 10:02:50,734 [MainThread  ] [INFO ]  step 7, loss 0.0\n",
      "2017-09-26 10:02:50,825 [MainThread  ] [INFO ]  step 8, loss 0.0\n",
      "2017-09-26 10:02:50,831 [MainThread  ] [INFO ]  step 9, loss 0.0\n",
      "2017-09-26 10:02:50,837 [MainThread  ] [INFO ]  step 10, loss 0.0\n",
      "2017-09-26 10:02:50,842 [MainThread  ] [INFO ]  step 11, loss 0.0\n",
      "2017-09-26 10:02:50,848 [MainThread  ] [INFO ]  step 12, loss 0.0\n",
      "2017-09-26 10:02:50,855 [MainThread  ] [INFO ]  step 13, loss 0.0\n",
      "2017-09-26 10:02:50,865 [MainThread  ] [INFO ]  step 14, loss 0.0\n",
      "2017-09-26 10:02:50,874 [MainThread  ] [INFO ]  step 15, loss 0.0\n",
      "2017-09-26 10:02:50,879 [MainThread  ] [INFO ]  step 16, loss 0.0\n",
      "2017-09-26 10:02:50,885 [MainThread  ] [INFO ]  step 17, loss 0.0\n",
      "2017-09-26 10:02:50,891 [MainThread  ] [INFO ]  step 18, loss 0.0\n",
      "2017-09-26 10:02:50,897 [MainThread  ] [INFO ]  step 19, loss 0.0\n",
      "2017-09-26 10:02:50,903 [MainThread  ] [INFO ]  step 20, loss 0.0\n",
      "2017-09-26 10:02:50,909 [MainThread  ] [INFO ]  step 21, loss 0.0\n",
      "2017-09-26 10:02:50,916 [MainThread  ] [INFO ]  step 22, loss 0.0\n",
      "2017-09-26 10:02:50,924 [MainThread  ] [INFO ]  step 23, loss 0.0\n",
      "2017-09-26 10:02:50,930 [MainThread  ] [INFO ]  step 24, loss 0.0\n",
      "2017-09-26 10:02:50,936 [MainThread  ] [INFO ]  step 25, loss 0.0\n",
      "2017-09-26 10:02:50,942 [MainThread  ] [INFO ]  step 26, loss 0.0\n",
      "2017-09-26 10:02:50,948 [MainThread  ] [INFO ]  step 27, loss 0.0\n",
      "2017-09-26 10:02:50,953 [MainThread  ] [INFO ]  step 28, loss 0.0\n",
      "2017-09-26 10:02:50,963 [MainThread  ] [INFO ]  step 29, loss 0.0\n",
      "2017-09-26 10:02:50,967 [MainThread  ] [INFO ]  step 30, loss 0.0\n",
      "2017-09-26 10:02:51,062 [MainThread  ] [INFO ]  step 31, loss 0.0\n",
      "2017-09-26 10:02:51,157 [MainThread  ] [INFO ]  step 32, loss 0.0\n",
      "2017-09-26 10:02:51,163 [MainThread  ] [INFO ]  step 33, loss 0.0\n",
      "2017-09-26 10:02:51,169 [MainThread  ] [INFO ]  step 34, loss 0.0\n",
      "2017-09-26 10:02:51,175 [MainThread  ] [INFO ]  step 35, loss 0.0\n",
      "2017-09-26 10:02:51,182 [MainThread  ] [INFO ]  step 36, loss 0.0\n",
      "2017-09-26 10:02:51,189 [MainThread  ] [INFO ]  step 37, loss 0.0\n",
      "2017-09-26 10:02:51,195 [MainThread  ] [INFO ]  step 38, loss 0.0\n",
      "2017-09-26 10:02:51,201 [MainThread  ] [INFO ]  step 39, loss 0.0\n",
      "2017-09-26 10:02:51,207 [MainThread  ] [INFO ]  step 40, loss 0.0\n",
      "2017-09-26 10:02:51,215 [MainThread  ] [INFO ]  step 41, loss 0.0\n",
      "2017-09-26 10:02:51,222 [MainThread  ] [INFO ]  step 42, loss 0.0\n",
      "2017-09-26 10:02:51,227 [MainThread  ] [INFO ]  step 43, loss 0.0\n",
      "2017-09-26 10:02:51,234 [MainThread  ] [INFO ]  step 44, loss 0.0\n",
      "2017-09-26 10:02:51,241 [MainThread  ] [INFO ]  step 45, loss 0.0\n",
      "2017-09-26 10:02:51,246 [MainThread  ] [INFO ]  step 46, loss 0.0\n",
      "2017-09-26 10:02:51,251 [MainThread  ] [INFO ]  step 47, loss 0.0\n",
      "2017-09-26 10:02:51,257 [MainThread  ] [INFO ]  step 48, loss 0.0\n",
      "2017-09-26 10:02:51,264 [MainThread  ] [INFO ]  step 49, loss 0.0\n",
      "2017-09-26 10:02:51,269 [MainThread  ] [INFO ]  step 50, loss 0.0\n",
      "2017-09-26 10:02:51,361 [MainThread  ] [INFO ]  step 51, loss 0.0\n",
      "2017-09-26 10:02:51,367 [MainThread  ] [INFO ]  step 52, loss 0.0\n",
      "2017-09-26 10:02:51,376 [MainThread  ] [INFO ]  step 53, loss 0.0\n",
      "2017-09-26 10:02:51,383 [MainThread  ] [INFO ]  step 54, loss 0.0\n",
      "2017-09-26 10:02:51,388 [MainThread  ] [INFO ]  step 55, loss 0.0\n",
      "2017-09-26 10:02:51,394 [MainThread  ] [INFO ]  step 56, loss 0.0\n",
      "2017-09-26 10:02:51,400 [MainThread  ] [INFO ]  step 57, loss 0.0\n",
      "2017-09-26 10:02:51,406 [MainThread  ] [INFO ]  step 58, loss 0.0\n",
      "2017-09-26 10:02:51,414 [MainThread  ] [INFO ]  step 59, loss 0.0\n",
      "2017-09-26 10:02:51,419 [MainThread  ] [INFO ]  step 60, loss 0.0\n",
      "2017-09-26 10:02:51,425 [MainThread  ] [INFO ]  step 61, loss 0.0\n",
      "2017-09-26 10:02:51,431 [MainThread  ] [INFO ]  step 62, loss 0.0\n",
      "2017-09-26 10:02:51,437 [MainThread  ] [INFO ]  step 63, loss 0.0\n",
      "2017-09-26 10:02:51,442 [MainThread  ] [INFO ]  step 64, loss 0.0\n",
      "2017-09-26 10:02:51,450 [MainThread  ] [INFO ]  step 65, loss 0.0\n",
      "2017-09-26 10:02:51,456 [MainThread  ] [INFO ]  step 66, loss 0.0\n",
      "2017-09-26 10:02:51,462 [MainThread  ] [INFO ]  step 67, loss 0.0\n",
      "2017-09-26 10:02:51,467 [MainThread  ] [INFO ]  step 68, loss 0.0\n",
      "2017-09-26 10:02:51,472 [MainThread  ] [INFO ]  step 69, loss 0.0\n",
      "2017-09-26 10:02:51,476 [MainThread  ] [INFO ]  step 70, loss 0.0\n",
      "2017-09-26 10:02:51,483 [MainThread  ] [INFO ]  step 71, loss 0.0\n",
      "2017-09-26 10:02:51,488 [MainThread  ] [INFO ]  step 72, loss 0.0\n",
      "2017-09-26 10:02:51,578 [MainThread  ] [INFO ]  step 73, loss 0.0\n",
      "2017-09-26 10:02:51,585 [MainThread  ] [INFO ]  step 74, loss 0.0\n",
      "2017-09-26 10:02:51,592 [MainThread  ] [INFO ]  step 75, loss 0.0\n",
      "2017-09-26 10:02:51,598 [MainThread  ] [INFO ]  step 76, loss 0.0\n",
      "2017-09-26 10:02:51,603 [MainThread  ] [INFO ]  step 77, loss 0.0\n",
      "2017-09-26 10:02:51,695 [MainThread  ] [INFO ]  step 78, loss 0.0\n",
      "2017-09-26 10:02:51,702 [MainThread  ] [INFO ]  step 79, loss 0.0\n",
      "2017-09-26 10:02:51,708 [MainThread  ] [INFO ]  step 80, loss 0.0\n",
      "2017-09-26 10:02:51,713 [MainThread  ] [INFO ]  step 81, loss 0.0\n",
      "2017-09-26 10:02:51,719 [MainThread  ] [INFO ]  step 82, loss 0.0\n",
      "2017-09-26 10:02:51,728 [MainThread  ] [INFO ]  step 83, loss 0.0\n",
      "2017-09-26 10:02:51,733 [MainThread  ] [INFO ]  step 84, loss 0.0\n",
      "2017-09-26 10:02:51,738 [MainThread  ] [INFO ]  step 85, loss 0.0\n",
      "2017-09-26 10:02:51,743 [MainThread  ] [INFO ]  step 86, loss 0.0\n",
      "2017-09-26 10:02:51,748 [MainThread  ] [INFO ]  step 87, loss 0.0\n",
      "2017-09-26 10:02:51,757 [MainThread  ] [INFO ]  step 88, loss 0.0\n",
      "2017-09-26 10:02:51,763 [MainThread  ] [INFO ]  step 89, loss 0.0\n",
      "2017-09-26 10:02:51,774 [MainThread  ] [INFO ]  step 90, loss 0.0\n",
      "2017-09-26 10:02:51,780 [MainThread  ] [INFO ]  step 91, loss 0.0\n",
      "2017-09-26 10:02:51,787 [MainThread  ] [INFO ]  step 92, loss 0.0\n",
      "2017-09-26 10:02:51,794 [MainThread  ] [INFO ]  step 93, loss 0.0\n",
      "2017-09-26 10:02:51,889 [MainThread  ] [INFO ]  step 94, loss 0.0\n",
      "2017-09-26 10:02:51,897 [MainThread  ] [INFO ]  step 95, loss 0.0\n",
      "2017-09-26 10:02:51,909 [MainThread  ] [INFO ]  step 96, loss 0.0\n",
      "2017-09-26 10:02:51,915 [MainThread  ] [INFO ]  step 97, loss 0.0\n",
      "2017-09-26 10:02:51,922 [MainThread  ] [INFO ]  step 98, loss 0.0\n",
      "2017-09-26 10:02:51,931 [MainThread  ] [INFO ]  step 99, loss 0.0\n"
     ]
    }
   ],
   "source": [
    "finished = False\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(0)\n",
    "    session_conf = tf.ConfigProto(\n",
    "        allow_soft_placement=True, log_device_placement=False)\n",
    "    sess = tf.Session(config=session_conf)    \n",
    "    with sess.as_default():\n",
    "        X = tf.placeholder('float32', (None, embedding_size), name='X')\n",
    "        phase = tf.placeholder(tf.bool, name='phase') \n",
    "        \n",
    "        init_local = tf.local_variables_initializer()\n",
    "        init_global = tf.global_variables_initializer()\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        # do not restore before global initialization, otherwise all weights are set to default !!!\n",
    "        saver = tf.train.import_meta_graph(last_model(model_dir), input_map={'X':X})\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
    "        graph = tf.get_default_graph()\n",
    "\n",
    "        op_name = 'optimize/loss/doc_embed_normalized'\n",
    "        doc_embed_normalized = graph.get_operation_by_name(op_name).outputs[0]\n",
    "\n",
    "        anchor, positive, negative = tf.unstack(\n",
    "            tf.reshape(doc_embed_normalized, [-1, 3, sizes[-1]]),\n",
    "            3, 1)\n",
    "        _loss = train.triplet_loss(anchor, positive, negative)\n",
    "\n",
    "#         pprint([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "\n",
    "        test_batch = data_flow.gen_batches(docs, triples_test[:100*batch_size], batch_size)\n",
    "\n",
    "        step = 0\n",
    "        for step, X_test in enumerate(test_batch):\n",
    "            [batch_embeds, loss] = sess.run([doc_embed_normalized, _loss],\n",
    "                                           feed_dict = {phase: 0, 'X:0': X_test})\n",
    "            doc_embeds.append(batch_embeds)\n",
    "            logging.info('step %s, loss %s' % (step, loss))\n",
    "            step+=1\n",
    "        finished = True\n",
    "        \n",
    "except Exception as e:\n",
    "    logging.exception(\"test error\")\n",
    "#     send_email('notebook_url', subject='test error', body=e)\n",
    "finally:\n",
    "    if finished:\n",
    "#         send_email('notebook_url', subject='finished testing')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T06:13:08.863534Z",
     "start_time": "2017-09-26T06:13:08.842956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26726124  0.53452247  0.80178368]\n",
      " [ 0.45584232  0.56980288  0.6837635 ]\n",
      " [ 0.50257069  0.57436651  0.64616233]]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(0)\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "\n",
    "        arr = np.array([[1,2,3], [4,5,6], [7,8,9]], dtype=np.float32)\n",
    "        \n",
    "        m = tf.nn.l2_normalize(arr, dim=1)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        [res] = sess.run([m])\n",
    "        print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T06:14:08.393766Z",
     "start_time": "2017-09-26T06:14:08.389579Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26726124,  0.53452248,  0.80178373])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.,2.,3.])/np.sqrt(1+4+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T06:11:59.932594Z",
     "start_time": "2017-09-26T06:11:59.928246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999108555808"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.26726124**2 + 0.53452247**2 + 0.80178368**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
