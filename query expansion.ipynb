{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:00.919584Z",
     "start_time": "2017-07-29T16:58:42.206609Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:04.909986Z",
     "start_time": "2017-07-29T16:59:00.920782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-29 19:59:00,928 : INFO : loading Word2Vec object from ../data/vectors/w2v_model_300_w10\n",
      "2017-07-29 19:59:02,906 : INFO : loading wv recursively from ../data/vectors/w2v_model_300_w10.wv.* with mmap=None\n",
      "2017-07-29 19:59:02,907 : INFO : loading syn0 from ../data/vectors/w2v_model_300_w10.wv.syn0.npy with mmap=None\n",
      "2017-07-29 19:59:03,059 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-07-29 19:59:03,059 : INFO : loading syn1neg from ../data/vectors/w2v_model_300_w10.syn1neg.npy with mmap=None\n",
      "2017-07-29 19:59:03,207 : INFO : setting ignored attribute cum_table to None\n",
      "2017-07-29 19:59:03,208 : INFO : loaded ../data/vectors/w2v_model_300_w10\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load(join(DATA_FOLDER, 'vectors/w2v_model_300_w10'))\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:06.644813Z",
     "start_time": "2017-07-29T16:59:04.911416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-29 19:59:04,913 : INFO : loading Dictionary object from ../data/pure.dict\n",
      "2017-07-29 19:59:06,232 : INFO : loaded ../data/pure.dict\n",
      "2017-07-29 19:59:06,233 : INFO : loading TfidfModel object from ../data/tfidf_pure.model\n",
      "2017-07-29 19:59:06,641 : INFO : loaded ../data/tfidf_pure.model\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load(join(DATA_FOLDER, 'pure.dict'))\n",
    "tfidf = models.TfidfModel.load(join(DATA_FOLDER, 'tfidf_pure.model'))\n",
    "# !!!!!\n",
    "tfidf.normalize= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:06.866864Z",
     "start_time": "2017-07-29T16:59:06.645951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_docs = get_all_docs(DATA_FOLDER)\n",
    "val_docs = glob(join(DATA_FOLDER, 'validate/*.txt'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'автомобиль станция загород' vs 'данный патент представлять схема строениие и сооружение транспортная стоянка в сельская местность'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:06.877694Z",
     "start_time": "2017-07-29T16:59:06.868220Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sim_matrix(word_set1, word_set2, wv):\n",
    "    l1 = list(word_set1)\n",
    "    l2 = list(word_set2)\n",
    "    wv1 = wv[l1]\n",
    "    wv2 = wv[l2]\n",
    "    \n",
    "    arr = cosine_similarity(wv1, wv2)\n",
    "    \n",
    "    smat = pd.DataFrame(arr, index=l1, columns=l2)\n",
    "    return smat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:06.882389Z",
     "start_time": "2017-07-29T16:59:06.878790Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd(smat, tfidf_weights):\n",
    "    mins = np.amin(smat, axis=0)\n",
    "    return np.dot(mins, tfidf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:06.922500Z",
     "start_time": "2017-07-29T16:59:06.883513Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_tfidf_weights(val_docs, wv):\n",
    "    tweights = {}\n",
    "    for fname in tqdm(val_docs):\n",
    "        with open(fname, 'r') as f:\n",
    "            doc_text = f.read()\n",
    "        tokenized_filtered = [w for w in tokenize(doc_text) if w in wv]\n",
    "        doc_bow = dictionary.doc2bow(tokenized_filtered)\n",
    "        sorted_tfidf = sorted(tfidf[doc_bow], key=itemgetter(1), reverse=True)\n",
    "        sorted_tfidf = pd.DataFrame([(dictionary[k],v) for k,v in sorted_tfidf],\n",
    "                                   columns=['word', 'score'])\n",
    "        \n",
    "        name = path.splitext(basename(fname))[0]\n",
    "        tweights[name] = sorted_tfidf\n",
    "            \n",
    "    return tweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:06.934883Z",
     "start_time": "2017-07-29T16:59:06.923806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_queries_distances(doc_words, val_words, tweights):\n",
    "    dists = []\n",
    "    smat = sim_matrix(val_words, doc_words, wv)\n",
    "    for k, query in tweights.items():\n",
    "        if len(query) == 0:\n",
    "            dists.append(-99999999999)\n",
    "            continue\n",
    "        \n",
    "        qsmat = smat.loc[query.word, :]\n",
    "        dist = wmd(qsmat.T, query.score)\n",
    "        dists.append(dist)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:07.637369Z",
     "start_time": "2017-07-29T16:59:06.936171Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:00<00:00, 195.10it/s]\n"
     ]
    }
   ],
   "source": [
    "tweights = get_test_tfidf_weights(val_docs, wv)\n",
    "val_words = set(pd.concat([v.word for v in tweights.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:07.645150Z",
     "start_time": "2017-07-29T16:59:07.640349Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tweights['_01_98_2010120931A10010101RU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T16:59:07.696035Z",
     "start_time": "2017-07-29T16:59:07.646660Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ziped_files = sorted(glob(DATA_FOLDER + '/documents/*.gz'), key=natural_keys)\n",
    "\n",
    "def _calc(docs):        \n",
    "    doc_dists = []\n",
    "    for doc in tqdm(docs):\n",
    "        doc_words = set([w for sent in doc for w in sent if w in wv])\n",
    "        dists = doc_queries_distances(doc_words, val_words, tweights)\n",
    "\n",
    "        arg = np.argmax(dists)\n",
    "        doc_dists.append((arg, dists[arg]))\n",
    "    return doc_dists\n",
    "\n",
    "\n",
    "def calc_dists(fnames, wv):\n",
    "    doc_dists = []\n",
    "    for fn in fnames:\n",
    "        print(fn)\n",
    "        with GzipFile(fn, 'r') as myzip:\n",
    "            text = myzip.read()\n",
    "        docs = json.loads(text)\n",
    "        \n",
    "        parallelizer = Parallel(n_jobs=cpu_count)\n",
    "\n",
    "        # this iterator returns the functions to execute for each task\n",
    "        tasks_iterator = ( delayed(_calc)(docs_block) for \n",
    "                          docs_block in grouper(len(docs)//cpu_count, docs) )  \n",
    "        result = parallelizer( tasks_iterator )        \n",
    "        doc_dists += result\n",
    "            \n",
    "    return np.array(doc_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T17:05:35.922486Z",
     "start_time": "2017-07-29T17:00:12.801823Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data//documents/991.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [02:24<00:00,  2.04it/s]\n",
      "100%|██████████| 298/298 [02:24<00:00,  2.01it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.03it/s]t/s]\n",
      " 99%|█████████▉| 296/298 [02:25<00:00,  2.38it/s]\n",
      "100%|██████████| 298/298 [02:26<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data//documents/992.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 294/298 [02:23<00:01,  2.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.34it/s]t/s]\n",
      "100%|██████████| 298/298 [02:24<00:00,  2.19it/s]\n",
      "100%|██████████| 298/298 [02:25<00:00,  2.45it/s]\n",
      "100%|██████████| 298/298 [02:25<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data//documents/993.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 62/298 [00:29<02:11,  1.80it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aca5fdce57bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mziped_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-0b683bccaeab>\u001b[0m in \u001b[0;36mcalc_dists\u001b[0;34m(fnames, wv)\u001b[0m\n\u001b[1;32m     25\u001b[0m         tasks_iterator = ( delayed(_calc)(docs_block) for \n\u001b[1;32m     26\u001b[0m                           docs_block in grouper(len(docs)//cpu_count, docs) )  \n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelizer\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtasks_iterator\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdoc_dists\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_dists = calc_dists(ziped_files[-10:], wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T21:10:42.689027Z",
     "start_time": "2017-07-28T21:10:42.676548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(join(DATA_FOLDER, 'val_dists.npy'), val_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T10:29:20.289796Z",
     "start_time": "2017-07-29T10:29:19.973999Z"
    }
   },
   "source": [
    "TODO:\n",
    "* normalize = False in tfidf\n",
    "* first 2-3 sents of query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T10:21:42.320817Z",
     "start_time": "2017-07-29T10:21:42.316090Z"
    }
   },
   "outputs": [],
   "source": [
    "# fn = join(DATA_FOLDER, 'first2.json.gz')\n",
    "\n",
    "# with GzipFile(fn, 'r') as myzip:\n",
    "#     text = myzip.read()\n",
    "# docs = json.loads(text)\n",
    "# del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T10:26:23.252423Z",
     "start_time": "2017-07-29T10:26:23.241386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = join(DATA_FOLDER, 'first3_val.json.gz')\n",
    "\n",
    "with GzipFile(fn, 'r') as myzip:\n",
    "    text = myzip.read()\n",
    "val_documents = json.loads(text)\n",
    "del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T10:26:27.684864Z",
     "start_time": "2017-07-29T10:26:27.679522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T10:32:03.301370Z",
     "start_time": "2017-07-29T10:32:03.177780Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130it [00:00, 1610.34it/s]\n"
     ]
    }
   ],
   "source": [
    "tweights = {}\n",
    "for fname, doc in tqdm(zip(val_docs, val_documents)):\n",
    "    tokenized_filtered = [w for w in doc if w in wv]\n",
    "    doc_bow = dictionary.doc2bow(tokenized_filtered)\n",
    "    sorted_tfidf = sorted(tfidf[doc_bow], key=itemgetter(1), reverse=True)\n",
    "    sorted_tfidf = pd.DataFrame([(dictionary[k],v) for k,v in sorted_tfidf],\n",
    "                               columns=['word', 'score'])\n",
    "\n",
    "    name = path.splitext(basename(fname))[0]\n",
    "    tweights[name] = sorted_tfidf\n",
    "\n",
    "val_words = set(pd.concat([v.word for v in tweights.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T10:34:31.679495Z",
     "start_time": "2017-07-29T10:32:31.441801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data//documents/0.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 298/298 [01:54<00:00,  2.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.82it/s]t/s]\n",
      "100%|██████████| 298/298 [01:55<00:00,  2.77it/s]\n",
      "100%|██████████| 298/298 [01:56<00:00,  3.09it/s]\n",
      "100%|██████████| 298/298 [01:56<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dists = calc_dists(ziped_files[:1], wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T14:16:59.908715Z",
     "start_time": "2017-07-28T14:16:58.473047Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with GzipFile(ziped_files[0], 'r') as myzip:\n",
    "    text = myzip.read()\n",
    "docs = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T14:17:00.311401Z",
     "start_time": "2017-07-28T14:16:59.909824Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = docs[0]\n",
    "doc_words = set([w for sent in doc for w in sent if w in wv])\n",
    "dists = doc_queries_distances(doc_words, val_words, tweights)\n",
    "\n",
    "np.argmax(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T14:17:00.408612Z",
     "start_time": "2017-07-28T14:17:00.312581Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smat = sim_matrix(val_words, doc_words, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T13:53:27.564325Z",
     "start_time": "2017-07-28T13:53:19.951Z"
    },
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(doc, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T13:53:27.564910Z",
     "start_time": "2017-07-28T13:53:19.952Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T13:53:27.565429Z",
     "start_time": "2017-07-28T13:53:19.954Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(tweights.keys())[114]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
